{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02 : Construction du Pipeline de Prétraitement\n",
    "\n",
    "## Contexte\n",
    "\n",
    "**Objectif :** Créer un pipeline sklearn réutilisable et robuste pour préparer les données avant la modélisation.\n",
    "\n",
    "Un pipeline permet de :\n",
    "- Encapsuler toutes les étapes de prétraitement dans un objet unique\n",
    "- Garantir que les mêmes transformations sont appliquées sur train/valid/test\n",
    "- Éviter les fuites de données (data leakage)\n",
    "- Faciliter la mise en production\n",
    "\n",
    "---\n",
    "\n",
    "## Input\n",
    "\n",
    "**Fichier d'entrée :** `application_train_AGGREGATED.csv`\n",
    "- Créé par le Notebook 01\n",
    "- Shape attendu : (307 511 lignes, 797 colonnes)\n",
    "- Contient les données agrégées des 7 tables\n",
    "\n",
    "---\n",
    "\n",
    "## Étapes du pipeline\n",
    "\n",
    "### 1. Séparation X et y\n",
    "- `X` : Toutes les colonnes sauf `SK_ID_CURR` (identifiant) et `TARGET` (variable cible)\n",
    "- `y` : Variable binaire `TARGET` (0 = remboursement, 1 = défaut)\n",
    "\n",
    "### 2. Split train/validation\n",
    "- **Train** : 80% des données pour entraîner le modèle\n",
    "- **Validation** : 20% des données pour évaluer les performances\n",
    "- `stratify=y` : Maintient la même proportion de 0/1 dans train et valid\n",
    "- `random_state=42` : Reproductibilité des résultats\n",
    "\n",
    "### 3. Identification des types de variables\n",
    "- **Variables numériques** : int64, float64 (à standardiser)\n",
    "- **Variables catégorielles** : object, category (déjà encodées en One-Hot dans Notebook 01)\n",
    "\n",
    "### 4. ColumnTransformer\n",
    "Applique des transformations différentes selon le type de variable :\n",
    "\n",
    "**Pour les variables numériques :**\n",
    "- `SimpleImputer(strategy='median')` : Remplace les NaN par la médiane (robuste aux outliers)\n",
    "- `StandardScaler()` : Standardisation (moyenne=0, écart-type=1)\n",
    "\n",
    "**Pour les variables catégorielles :**\n",
    "- `SimpleImputer(strategy='constant', fill_value='missing')` : Remplace les NaN par 'missing'\n",
    "- Pas de scaling nécessaire (déjà en 0/1 après One-Hot Encoding)\n",
    "\n",
    "**Pourquoi standardiser les variables numériques ?**\n",
    "- Régression Logistique : Nécessite des variables à échelles comparables\n",
    "- Convergence plus rapide des algorithmes d'optimisation\n",
    "- Interprétation plus facile des coefficients\n",
    "\n",
    "**Pourquoi la médiane plutôt que la moyenne ?**\n",
    "- Plus robuste aux valeurs extrêmes (outliers)\n",
    "- Mieux adaptée aux distributions asymétriques\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Le notebook génère 3 fichiers joblib dans le dossier `artifacts/` :\n",
    "\n",
    "1. **preprocesseur.joblib** : Pipeline de prétraitement complet (ColumnTransformer)\n",
    "2. **data_split.joblib** : Tuple (X_train, X_valid, y_train, y_valid)\n",
    "3. **feature_names.joblib** : Liste des noms de features après transformation\n",
    "\n",
    "Ces fichiers seront réutilisés dans les notebooks suivants.\n",
    "\n",
    "---\n",
    "\n",
    "## Prévention du Data Leakage\n",
    "\n",
    "**Principe crucial :** Le prétraitement doit être ajusté (fit) UNIQUEMENT sur le train, puis appliqué (transform) sur train ET validation.\n",
    "\n",
    "### Approche CORRECTE (pas de data leakage)\n",
    "\n",
    "```\n",
    "Données complètes (X, y)\n",
    "|\n",
    "v\n",
    "SPLIT FIRST\n",
    "|\n",
    "+---+---+\n",
    "| |\n",
    "v v\n",
    "TRAIN VALID\n",
    "|\n",
    "v\n",
    "FIT preprocesseur\n",
    "(calcul médiane, mean, std)\n",
    "|\n",
    "+-------+-------+\n",
    "| |\n",
    "v v\n",
    "TRANSFORM TRANSFORM\n",
    "TRAIN VALID\n",
    "```\n",
    "\n",
    "**Exemple correct :**\n",
    "```python\n",
    "# 1. Split AVANT tout prétraitement\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "# 2. Fit sur train seulement\n",
    "preprocesseur.fit(X_train)\n",
    "\n",
    "# 3. Transform sur train ET valid\n",
    "X_train_processed = preprocesseur.transform(X_train)\n",
    "X_valid_processed = preprocesseur.transform(X_valid)\n",
    "```\n",
    "\n",
    "### Approche INCORRECTE (data leakage)\n",
    "\n",
    "```\n",
    "Données complètes (X, y)\n",
    "|\n",
    "v\n",
    "FIT preprocesseur ← ERREUR : utilise les données validation !\n",
    "(calcul médiane, mean, std)\n",
    "|\n",
    "v\n",
    "TRANSFORM\n",
    "|\n",
    "v\n",
    "SPLIT ← Trop tard, le modèle a déjà \"vu\" la validation\n",
    "|\n",
    "+---+---+\n",
    "| |\n",
    "v v\n",
    "TRAIN VALID\n",
    "```\n",
    "\n",
    "**Erreur à éviter :**\n",
    "```python\n",
    "# ERREUR : Fit sur toutes les données AVANT split\n",
    "preprocesseur.fit(X) # Le modèle \"voit\" les données validation !\n",
    "X_processed = preprocesseur.transform(X)\n",
    "X_train, X_valid = train_test_split(X_processed)\n",
    "```\n",
    "\n",
    "**Pourquoi c'est grave ?**\n",
    "- La médiane calculée sur toutes les données inclut les valeurs de validation\n",
    "- Le StandardScaler utilise la moyenne/écart-type de validation\n",
    "- Le modèle a indirectement accès à des informations de validation\n",
    "- Les performances mesurées sont artificiellement gonflées\n",
    "- En production, les performances réelles seront décevantes\n",
    "\n",
    "**Dans notre notebook, nous suivons la méthode CORRECTE !**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports réussis\n"
     ]
    }
   ],
   "source": [
    "# Imports des librairies nécessaires\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn : split et prétraitement\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sauvegarde des objets\n",
    "import joblib\n",
    "\n",
    "# Configuration visualisation\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print('Imports réussis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données (optimisé mémoire)\n",
    "\n",
    "**Source :** Fichier `application_train_AGGREGATED.csv` créé par le Notebook 01\n",
    "\n",
    "Ce fichier contient :\n",
    "- Les 307 511 clients du dataset train\n",
    "- Les 797 colonnes (122 initiales + 675 agrégées)\n",
    "- La variable cible `TARGET` (0 ou 1)\n",
    "\n",
    "**Optimisation mémoire :**\n",
    "- Conversion automatique des types pour réduire l'empreinte mémoire\n",
    "- float64 → float32 (divise la mémoire par 2)\n",
    "- int64 → int32 ou int16 selon les valeurs\n",
    "- Fichier original : ~1.4 GB en mémoire\n",
    "- Fichier optimisé : ~700 MB en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration des chemins :\n",
      " Données : data\\application_train_AGGREGATED.csv\n",
      " Artifacts : artifacts\n",
      "\n",
      "Vérification du fichier...\n",
      " Fichier trouvé : 1154.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Configuration des chemins\n",
    "DOSSIER_DATA = Path('./data')\n",
    "DOSSIER_ARTIFACTS = Path('./artifacts')\n",
    "\n",
    "# Créer le dossier artifacts s'il n'existe pas\n",
    "DOSSIER_ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "# Chemin du fichier agrégé\n",
    "CHEMIN_TRAIN = DOSSIER_DATA / 'application_train_AGGREGATED.csv'\n",
    "\n",
    "print(\"Configuration des chemins :\")\n",
    "print(f\" Données : {CHEMIN_TRAIN}\")\n",
    "print(f\" Artifacts : {DOSSIER_ARTIFACTS}\")\n",
    "\n",
    "print(\"\\nVérification du fichier...\")\n",
    "if CHEMIN_TRAIN.exists():\n",
    "    file_size = CHEMIN_TRAIN.stat().st_size / (1024**2)\n",
    "    print(f\" Fichier trouvé : {file_size:.1f} MB\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Fichier non trouvé : {CHEMIN_TRAIN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Réduit l'usage mémoire d'un DataFrame en convertissant les types de données.\n",
    "\n",
    "    float64 → float32 (divise par 2)\n",
    "    int64   → int32 / int16 / int8 selon min/max\n",
    "    \"\"\"\n",
    "\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mémoire initiale : {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            # Gestion des entiers\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "\n",
    "            # Gestion des floats\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Mémoire finale : {end_mem:.2f} MB\")\n",
    "        print(f\"Réduction : {100 * (start_mem - end_mem) / start_mem:.1f}%\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chargement des données par morceaux...\n",
      "(Cela peut prendre 3-5 minutes)\n",
      "\n",
      "Lecture du fichier par chunks de 20 000 lignes...\n",
      " Chunk 1 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 2 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 3 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 4 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 5 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 6 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 7 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 8 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 9 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 10 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 11 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 12 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 13 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 14 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 15 : 20,000 lignes chargées → optimisé (RAM économisée)\n",
      " Chunk 16 : 7,507 lignes chargées → optimisé (RAM économisée)\n",
      "\n",
      "Concaténation des chunks...\n",
      "\n",
      "Chargement réussi\n",
      " Shape : (307507, 796)\n",
      " Lignes : 307,507\n",
      " Colonnes : 796\n",
      "\n",
      "Optimisation mémoire finale...\n",
      " Mémoire utilisée : 920.5 MB\n",
      "\n",
      "Vérification de TARGET...\n",
      " Variable TARGET présente\n",
      " Distribution :\n",
      " Classe 0 : 91.9%\n",
      " Classe 1 : 8.1%\n",
      "\n",
      "Données prêtes pour le traitement\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données avec optimisation mémoire (par chunks)\n",
    "print(\"\\nChargement des données par morceaux...\")\n",
    "print(\"(Cela peut prendre 3-5 minutes)\\n\")\n",
    "\n",
    "# Paramètres de chargement (chunks plus petits pour économiser la RAM)\n",
    "chunk_size = 20000  # 20 000 lignes à la fois\n",
    "chunks = []\n",
    "\n",
    "print(\"Lecture du fichier par chunks de 20 000 lignes...\")\n",
    "\n",
    "try:\n",
    "    for i, chunk in enumerate(pd.read_csv(CHEMIN_TRAIN, chunksize=chunk_size, low_memory=False)):\n",
    "        print(f\" Chunk {i+1} : {len(chunk):,} lignes chargées\", end='')\n",
    "\n",
    "        # Optimisation immédiate de chaque chunk\n",
    "        chunk = reduce_mem_usage(chunk, verbose=False)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        print(\" → optimisé (RAM économisée)\")\n",
    "\n",
    "except MemoryError as e:\n",
    "    print(\"\\n\\nERREUR MÉMOIRE : Pas assez de RAM disponible\")\n",
    "    print(\"RAM nécessaire : ~4 GB\")\n",
    "    print(\"\\nActions recommandées :\")\n",
    "    print(\" 1. Fermez Google Chrome, Edge, WhatsApp, Dropbox\")\n",
    "    print(\" 2. Redémarrez Jupyter : Kernel → Restart\")\n",
    "    print(\" 3. Relancez le notebook\")\n",
    "    raise\n",
    "\n",
    "# Concaténation de tous les chunks\n",
    "print(\"\\nConcaténation des chunks...\")\n",
    "df_train = pd.concat(chunks, ignore_index=True)\n",
    "del chunks  # Libération mémoire\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\nChargement réussi\")\n",
    "print(f\" Shape : {df_train.shape}\")\n",
    "print(f\" Lignes : {df_train.shape[0]:,}\")\n",
    "print(f\" Colonnes : {df_train.shape[1]:,}\")\n",
    "\n",
    "# Optimisation finale\n",
    "print(\"\\nOptimisation mémoire finale...\")\n",
    "start_mem = df_train.memory_usage().sum() / 1024**2\n",
    "print(f\" Mémoire utilisée : {start_mem:.1f} MB\")\n",
    "\n",
    "# Vérification de la présence de TARGET\n",
    "print(\"\\nVérification de TARGET...\")\n",
    "if 'TARGET' in df_train.columns:\n",
    "    print(\" Variable TARGET présente\")\n",
    "    print(\" Distribution :\")\n",
    "    for val, pct in df_train['TARGET'].value_counts(normalize=True).items():\n",
    "        print(f\" Classe {val} : {pct*100:.1f}%\")\n",
    "else:\n",
    "    raise ValueError(\"La colonne TARGET est absente !\")\n",
    "\n",
    "print(\"\\nDonnées prêtes pour le traitement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse exploratoire rapide\n",
    "\n",
    "### Distribution de la variable cible\n",
    "\n",
    "**Déséquilibre des classes :**\n",
    "- Classe 0 (remboursement) : environ 92% des clients\n",
    "- Classe 1 (défaut) : environ 8% des clients\n",
    "\n",
    "Ce fort déséquilibre implique que :\n",
    "- L'accuracy n'est PAS une bonne métrique (un modèle prédisant toujours 0 aurait 92% d'accuracy !)\n",
    "- Il faut utiliser l'AUC (Area Under Curve) comme métrique principale\n",
    "- Des techniques comme SMOTE ou class_weight peuvent améliorer les performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ratio de déséquilibre : 1 défaut pour 11.4 remboursements\n"
     ]
    }
   ],
   "source": [
    "# Visualisation de la distribution de TARGET\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "target_counts = df_train['TARGET'].value_counts()\n",
    "target_pct = df_train['TARGET'].value_counts(normalize=True) * 100\n",
    "\n",
    "ax.bar(['Remboursement (0)', 'Défaut (1)'], target_counts, \n",
    "       color=['#2ecc71', '#e74c3c'])\n",
    "ax.set_ylabel('Nombre de clients')\n",
    "ax.set_title('Distribution de la variable TARGET\\n(Déséquilibre : 92% / 8%)')\n",
    "\n",
    "# Ajout des pourcentages sur les barres\n",
    "for i, (count, pct) in enumerate(zip(target_counts, target_pct)):\n",
    "    ax.text(i, count + 5000, f'{pct:.1f}%\\n({count:,})',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRatio de déséquilibre : 1 défaut pour {target_counts[0] / target_counts[1]:.1f} remboursements\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valeurs manquantes\n",
    "\n",
    "Les valeurs manquantes (NaN) sont fréquentes dans ce dataset pour plusieurs raisons :\n",
    "- Client n'a pas de crédit bureau → features BURO_* = NaN\n",
    "- Client n'a jamais demandé de crédit chez Home Credit → features PREV_* = NaN\n",
    "- Agrégation sur des groupes vides → NaN\n",
    "\n",
    "**Stratégie de gestion :**\n",
    "- Variables numériques : Imputation par la médiane (robuste)\n",
    "- Variables catégorielles : Imputation par 'missing' (catégorie spéciale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques sur les valeurs manquantes :\n",
      " Nombre de colonnes avec NaN : 616 / 796\n",
      " Colonnes avec >50% NaN : 236\n",
      "\n",
      "Top 10 des colonnes avec le plus de NaN :\n",
      "                          Colonne  NaN_count  NaN_percent\n",
      "   REFUSED_RATE_DOWN_PAYMENT_MEAN     262339    85.311554\n",
      "    REFUSED_RATE_DOWN_PAYMENT_MAX     262339    85.311554\n",
      "    REFUSED_RATE_DOWN_PAYMENT_MIN     262339    85.311554\n",
      "    REFUSED_AMT_DOWN_PAYMENT_MEAN     262339    85.311554\n",
      "     REFUSED_AMT_DOWN_PAYMENT_MAX     262339    85.311554\n",
      "     REFUSED_AMT_DOWN_PAYMENT_MIN     262339    85.311554\n",
      "      REFUSED_APP_CREDIT_PERC_VAR     258350    84.014348\n",
      "       CC_AMT_PAYMENT_CURRENT_VAR     246888    80.286953\n",
      "CC_AMT_DRAWINGS_OTHER_CURRENT_VAR     246814    80.262888\n",
      "  CC_AMT_DRAWINGS_ATM_CURRENT_VAR     246814    80.262888\n"
     ]
    }
   ],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "missing_values = df_train.isnull().sum()\n",
    "missing_percent = (missing_values / len(df_train)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Colonne': missing_values.index,\n",
    "    'NaN_count': missing_values.values,\n",
    "    'NaN_percent': missing_percent.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['NaN_count'] > 0].sort_values('NaN_percent', ascending=False)\n",
    "\n",
    "print(\"\\nStatistiques sur les valeurs manquantes :\")\n",
    "print(f\" Nombre de colonnes avec NaN : {len(missing_df)} / {df_train.shape[1]}\")\n",
    "print(f\" Colonnes avec >50% NaN : {len(missing_df[missing_df['NaN_percent'] > 50])}\")\n",
    "\n",
    "print(\"\\nTop 10 des colonnes avec le plus de NaN :\")\n",
    "print(missing_df.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Séparation X et y\n",
    "\n",
    "**Variables à exclure :**\n",
    "- `SK_ID_CURR` : Identifiant client (pas prédictif)\n",
    "- `TARGET` : Variable cible (à prédire)\n",
    "\n",
    "**Toutes les autres colonnes sont des features pour la prédiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Séparation X et y...\n",
      "\n",
      "Résultat de la séparation :\n",
      " X shape : (307507, 794)\n",
      " - 307,507 échantillons (clients)\n",
      " - 794 features\n",
      " y shape : (307507,)\n",
      " - Distribution : {0: 282682, 1: 24825}\n",
      "\n",
      "Mémoire libérée (df_train supprimé)\n"
     ]
    }
   ],
   "source": [
    "# Séparation X (features) et y (target)\n",
    "print(\"\\nSéparation X et y...\")\n",
    "\n",
    "# Colonnes à exclure de X\n",
    "cols_to_exclude = ['SK_ID_CURR', 'TARGET']\n",
    "cols_to_exclude = [col for col in cols_to_exclude if col in df_train.columns]\n",
    "\n",
    "# X : toutes les features sauf SK_ID_CURR et TARGET\n",
    "X = df_train.drop(columns=cols_to_exclude)\n",
    "\n",
    "# y : variable cible\n",
    "y = df_train['TARGET']\n",
    "\n",
    "print(f\"\\nRésultat de la séparation :\")\n",
    "print(f\" X shape : {X.shape}\")\n",
    "print(f\" - {X.shape[0]:,} échantillons (clients)\")\n",
    "print(f\" - {X.shape[1]:,} features\")\n",
    "print(f\" y shape : {y.shape}\")\n",
    "print(f\" - Distribution : {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Libération mémoire\n",
    "del df_train\n",
    "import gc\n",
    "gc.collect()\n",
    "print(f\"\\nMémoire libérée (df_train supprimé)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nettoyage des valeurs infinies\n",
    "\n",
    "**Problème détecté :** Les divisions dans le Notebook 01 peuvent créer des valeurs infinies (Inf) quand le dénominateur est zéro.\n",
    "\n",
    "**Exemples :**\n",
    "```python\n",
    "INCOME_CREDIT_PERC = AMT_INCOME_TOTAL / AMT_CREDIT\n",
    "# Si AMT_CREDIT = 0 → Inf\n",
    "\n",
    "ANNUITY_INCOME_PERC = AMT_ANNUITY / AMT_INCOME_TOTAL\n",
    "# Si AMT_INCOME_TOTAL = 0 → Inf\n",
    "```\n",
    "\n",
    "**Solution :** Remplacer toutes les valeurs Inf par NaN colonne par colonne (pour économiser la mémoire)\n",
    "- Le SimpleImputer gérera ensuite ces NaN avec la médiane\n",
    "- Évite l'erreur \"Input X contains infinity\" dans StandardScaler\n",
    "\n",
    "**Impact :** Les Inf sont traités comme des valeurs manquantes, ce qui est plus sûr que de les garder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nettoyage des valeurs infinies...\n",
      " Valeurs Inf détectées : 20\n",
      " Colonnes nettoyées : 3\n",
      " Valeurs Inf après nettoyage : 0\n",
      " Ces valeurs seront imputées par la médiane dans le preprocessing\n",
      "\n",
      "Nettoyage terminé\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des valeurs infinies (colonne par colonne pour économiser la RAM)\n",
    "print(\"\\nNettoyage des valeurs infinies...\")\n",
    "\n",
    "# Comptage des Inf avant nettoyage\n",
    "inf_count_before = 0\n",
    "for col in X.select_dtypes(include=[np.number]).columns:\n",
    "    inf_count_before += np.isinf(X[col]).sum()\n",
    "\n",
    "print(f\" Valeurs Inf détectées : {inf_count_before:,}\")\n",
    "\n",
    "if inf_count_before > 0:\n",
    "    # Remplacement Inf par NaN colonne par colonne (économise la RAM)\n",
    "    cols_with_inf = []\n",
    "    for col in X.select_dtypes(include=[np.number]).columns:\n",
    "        if np.isinf(X[col]).any():\n",
    "            X[col] = X[col].replace([np.inf, -np.inf], np.nan)\n",
    "            cols_with_inf.append(col)\n",
    "\n",
    "    print(f\" Colonnes nettoyées : {len(cols_with_inf)}\")\n",
    "\n",
    "    # Vérification après nettoyage\n",
    "    inf_count_after = 0\n",
    "    for col in X.select_dtypes(include=[np.number]).columns:\n",
    "        inf_count_after += np.isinf(X[col]).sum()\n",
    "\n",
    "    print(f\" Valeurs Inf après nettoyage : {inf_count_after}\")\n",
    "\n",
    "else:\n",
    "    print(\" Aucune valeur Inf à nettoyer\")\n",
    "\n",
    "print(\" Ces valeurs seront imputées par la médiane dans le preprocessing\")\n",
    "print(\"\\nNettoyage terminé\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split Train / Validation\n",
    "\n",
    "**Flux de données complet :**\n",
    "\n",
    "```\n",
    "application_train_AGGREGATED.csv\n",
    "(307 511 × 797)\n",
    "|\n",
    "v\n",
    "Séparation X / y\n",
    "|\n",
    "+-----------+-----------+\n",
    "| |\n",
    "v v\n",
    "X (795 features) y (TARGET)\n",
    "| |\n",
    "+----------+------------+\n",
    "|\n",
    "v\n",
    "train_test_split()\n",
    "test_size=0.2, stratify=y\n",
    "|\n",
    "+----------+----------+\n",
    "| |\n",
    "v v\n",
    "TRAIN SET VALIDATION SET\n",
    "80% (246 008) 20% (61 503)\n",
    "| |\n",
    "v v\n",
    "X_train X_valid\n",
    "y_train y_valid\n",
    "(92% class 0) (92% class 0)\n",
    "(8% class 1) (8% class 1)\n",
    "```\n",
    "\n",
    "**Paramètres du split :**\n",
    "- `test_size=0.2` : 80% train, 20% validation\n",
    "- `random_state=42` : Reproductibilité des résultats\n",
    "- `stratify=y` : Maintient la proportion 92/8 dans train ET validation\n",
    "\n",
    "**Pourquoi stratify ?**\n",
    "Sans stratification, le validation set pourrait avoir une proportion différente de défauts (ex: 85/15 ou 95/5), ce qui fausserait complètement l'évaluation du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split train/validation (80/20)...\n",
      "\n",
      "Résultat du split :\n",
      "\n",
      "Train set :\n",
      " X_train shape : (246005, 794)\n",
      " y_train shape : (246005,)\n",
      " y_train distribution : \n",
      "TARGET\n",
      "0    0.91927\n",
      "1    0.08073\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation set :\n",
      " X_valid shape : (61502, 794)\n",
      " y_valid shape : (61502,)\n",
      " y_valid distribution : \n",
      "TARGET\n",
      "0    0.919271\n",
      "1    0.080729\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Vérification stratification : OK (proportions identiques)\n"
     ]
    }
   ],
   "source": [
    "# Split train/validation avec stratification\n",
    "print(\"\\nSplit train/validation (80/20)...\")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintient la proportion 92/8\n",
    ")\n",
    "\n",
    "print(\"\\nRésultat du split :\")\n",
    "\n",
    "print(\"\\nTrain set :\")\n",
    "print(f\" X_train shape : {X_train.shape}\")\n",
    "print(f\" y_train shape : {y_train.shape}\")\n",
    "print(f\" y_train distribution : \\n{y_train.value_counts(normalize=True)}\")\n",
    "\n",
    "print(\"\\nValidation set :\")\n",
    "print(f\" X_valid shape : {X_valid.shape}\")\n",
    "print(f\" y_valid shape : {y_valid.shape}\")\n",
    "print(f\" y_valid distribution : \\n{y_valid.value_counts(normalize=True)}\")\n",
    "\n",
    "print(\"\\nVérification stratification : OK (proportions identiques)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identification des types de variables\n",
    "\n",
    "**Variables numériques** (int64, float64) :\n",
    "- Nécessitent imputation (médiane) et standardisation\n",
    "- Exemples : AMT_INCOME_TOTAL, DAYS_BIRTH, BURO_DAYS_CREDIT_MEAN\n",
    "\n",
    "**Variables catégorielles** (object) :\n",
    "- Déjà encodées en One-Hot dans le Notebook 01\n",
    "- Nécessitent seulement imputation ('missing')\n",
    "- Exemples : NAME_EDUCATION_TYPE_Higher education, FLAG_OWN_CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identification des types de variables...\n",
      "\n",
      "Résultat :\n",
      " Variables numériques : 3\n",
      " Exemples : ['PREV_APP_CREDIT_PERC_MAX', 'REFUSED_APP_CREDIT_PERC_MAX', 'INSTAL_PAYMENT_PERC_MAX']\n",
      " Variables catégorielles : 16\n",
      " Exemples : ['CC_NAME_CONTRACT_STATUS_Active_MIN', 'CC_NAME_CONTRACT_STATUS_Active_MAX', 'CC_NAME_CONTRACT_STATUS_Approved_MIN', 'CC_NAME_CONTRACT_STATUS_Approved_MAX', 'CC_NAME_CONTRACT_STATUS_Completed_MIN']\n",
      "\n",
      "Total : 19 features (cohérent avec X_train.shape[1] = 794)\n"
     ]
    }
   ],
   "source": [
    "# Identification des types de colonnes\n",
    "print(\"\\nIdentification des types de variables...\")\n",
    "\n",
    "# Variables numériques\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Variables catégorielles (normalement aucune après One-Hot Encoding dans Notebook 01)\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"\\nRésultat :\")\n",
    "print(f\" Variables numériques : {len(numeric_features)}\")\n",
    "print(f\" Exemples : {numeric_features[:5]}\")\n",
    "\n",
    "print(f\" Variables catégorielles : {len(categorical_features)}\")\n",
    "if len(categorical_features) > 0:\n",
    "    print(f\" Exemples : {categorical_features[:5]}\")\n",
    "else:\n",
    "    print(\" Aucune (toutes encodées en One-Hot dans Notebook 01)\")\n",
    "\n",
    "# Vérification\n",
    "total_features = len(numeric_features) + len(categorical_features)\n",
    "print(f\"\\nTotal : {total_features} features (cohérent avec X_train.shape[1] = {X_train.shape[1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construction du ColumnTransformer\n",
    "\n",
    "**Architecture du preprocessing pipeline :**\n",
    "\n",
    "```\n",
    "X_train (246 008 lignes × 795 colonnes)\n",
    "|\n",
    "v\n",
    "ColumnTransformer\n",
    "|\n",
    "+---------------+---------------+\n",
    "| |\n",
    "v v\n",
    "Variables NUMÉRIQUES Variables CATÉGORIELLES\n",
    "(795 colonnes) (0 colonnes)\n",
    "| |\n",
    "v v\n",
    "+-------------------+ +-------------------+\n",
    "| SimpleImputer | | SimpleImputer |\n",
    "| strategy='median'| | fill='missing' |\n",
    "+-------------------+ +-------------------+\n",
    "| |\n",
    "v |\n",
    "+-------------------+ |\n",
    "| StandardScaler() | |\n",
    "| mean=0, std=1 | |\n",
    "+-------------------+ |\n",
    "| |\n",
    "+---------------+---------------+\n",
    "|\n",
    "v\n",
    "X_train_processed (array numpy)\n",
    "- Pas de NaN\n",
    "- Variables centrées et réduites\n",
    "- Prêt pour modélisation\n",
    "```\n",
    "\n",
    "**Avantages du ColumnTransformer :**\n",
    "- Applique automatiquement les transformations sur les bonnes colonnes\n",
    "- Peut être sauvegardé et rechargé (joblib)\n",
    "- S'intègre avec sklearn.pipeline.Pipeline\n",
    "- Évite les erreurs de transformation manuelle\n",
    "\n",
    "**Note :** Dans notre cas, toutes les variables sont numériques car le One-Hot Encoding a été fait dans le Notebook 01. Les variables catégorielles (NAME_EDUCATION_TYPE, etc.) ont été transformées en colonnes binaires (0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construction du pipeline de prétraitement...\n",
      "\n",
      "Pipeline créé avec succès\n",
      " Transformations numériques : 3 colonnes\n",
      " - Imputation : médiane\n",
      " - Scaling : StandardScaler\n",
      " Transformations catégorielles : 16 colonnes\n",
      " - Imputation : 'missing'\n",
      " - OneHotEncoding : drop='first'\n",
      " - Imputation finale : 0 (pour NaN créés par OHE)\n"
     ]
    }
   ],
   "source": [
    "# Construction du ColumnTransformer\n",
    "print(\"\\nConstruction du pipeline de prétraitement...\")\n",
    "\n",
    "# Pipeline pour les variables numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Imputation par la médiane\n",
    "    ('scaler', StandardScaler())                    # Standardisation\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Fonction pour convertir tout en string\n",
    "def convert_to_string(X):\n",
    "    \"\"\"Convertit toutes les valeurs en string pour OneHotEncoder\"\"\"\n",
    "    import pandas as pd\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return X.astype(str)\n",
    "    else:\n",
    "        return pd.DataFrame(X).astype(str).values\n",
    "\n",
    "# Pipeline pour les variables catégorielles\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('to_string', FunctionTransformer(convert_to_string)),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "    ('imputer_final', SimpleImputer(strategy='constant', fill_value=0))  # Impute NaN créés par OHE\n",
    "])\n",
    "\n",
    "# Assemblage dans le ColumnTransformer\n",
    "transformers = [\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "]\n",
    "\n",
    "if len(categorical_features) > 0:\n",
    "    transformers.append(('cat', categorical_transformer, categorical_features))\n",
    "\n",
    "preprocesseur = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder='passthrough'  # Garde les colonnes non spécifiées\n",
    ")\n",
    "\n",
    "print(\"\\nPipeline créé avec succès\")\n",
    "print(f\" Transformations numériques : {len(numeric_features)} colonnes\")\n",
    "print(\" - Imputation : médiane\")\n",
    "print(\" - Scaling : StandardScaler\")\n",
    "\n",
    "if len(categorical_features) > 0:\n",
    "    print(f\" Transformations catégorielles : {len(categorical_features)} colonnes\")\n",
    "    print(\" - Imputation : 'missing'\")\n",
    "    print(\" - OneHotEncoding : drop='first'\")\n",
    "    print(\" - Imputation finale : 0 (pour NaN créés par OHE)\")\n",
    "else:\n",
    "    print(\" Aucune variable catégorielle (tout a été encodé dans Notebook 01)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit du preprocesseur sur le train set\n",
    "\n",
    "**ATTENTION : Point critique pour éviter le data leakage**\n",
    "\n",
    "Le fit du prétraitement doit être fait **UNIQUEMENT** sur le train set.\n",
    "\n",
    "Lors du fit :\n",
    "- `SimpleImputer` calcule la médiane des variables numériques (sur train seulement)\n",
    "- `StandardScaler` calcule la moyenne et l'écart-type (sur train seulement)\n",
    "\n",
    "Puis lors du transform :\n",
    "- Ces statistiques (calculées sur train) sont appliquées sur train ET validation\n",
    "\n",
    "**Pourquoi c'est important ?**\n",
    "Si on fit sur toutes les données, le modèle \"voit\" des informations du validation set, ce qui surestime artificiellement les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit du preprocesseur sur le train set...\n",
      "(Calcul des médianes et paramètres de standardisation)\n",
      "\n",
      "Fit terminé avec succès\n",
      " Médianes calculées sur 246,005 échantillons\n",
      " Paramètres de scaling calculés sur 246,005 échantillons\n",
      "\n",
      "Prêt pour transform sur train et validation\n"
     ]
    }
   ],
   "source": [
    "# Fit du preprocesseur sur X_train UNIQUEMENT\n",
    "print(\"\\nFit du preprocesseur sur le train set...\")\n",
    "print(\"(Calcul des médianes et paramètres de standardisation)\")\n",
    "\n",
    "preprocesseur.fit(X_train)\n",
    "\n",
    "print(f\"\\nFit terminé avec succès\")\n",
    "print(f\" Médianes calculées sur {X_train.shape[0]:,} échantillons\")\n",
    "print(f\" Paramètres de scaling calculés sur {X_train.shape[0]:,} échantillons\")\n",
    "print(f\"\\nPrêt pour transform sur train et validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Transform sur train et validation\n",
    "\n",
    "**Application des transformations :**\n",
    "- Le préprocesseur applique les transformations fit sur train\n",
    "- Les NaN sont remplacés par les médianes du train\n",
    "- Les variables sont standardisées avec la moyenne/écart-type du train\n",
    "\n",
    "**Format de sortie :**\n",
    "- Arrays numpy (pas de DataFrames)\n",
    "- Shape : (n_samples, n_features)\n",
    "- Toutes les valeurs sont numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transform des données...\n",
      "\n",
      "Transform terminé avec succès\n",
      "\n",
      "Train set transformé :\n",
      " Shape : (246005, 804)\n",
      " Type : <class 'numpy.ndarray'>\n",
      " Dtype : float64\n",
      " NaN restants : 47804703\n",
      "\n",
      "Validation set transformé :\n",
      " Shape : (61502, 804)\n",
      " Type : <class 'numpy.ndarray'>\n",
      " Dtype : float64\n",
      " NaN restants : 11964490\n",
      "\n",
      "ATTENTION : Des NaN persistent après preprocessing !\n"
     ]
    }
   ],
   "source": [
    "# Transform sur train et validation\n",
    "print(\"\\nTransform des données...\")\n",
    "\n",
    "X_train_processed = preprocesseur.transform(X_train)\n",
    "X_valid_processed = preprocesseur.transform(X_valid)\n",
    "\n",
    "print(\"\\nTransform terminé avec succès\")\n",
    "\n",
    "print(\"\\nTrain set transformé :\")\n",
    "print(f\" Shape : {X_train_processed.shape}\")\n",
    "print(f\" Type : {type(X_train_processed)}\")\n",
    "print(f\" Dtype : {X_train_processed.dtype}\")\n",
    "\n",
    "# Vérification des NaN (avec gestion d'erreur)\n",
    "try:\n",
    "    nan_count_train = np.isnan(X_train_processed).sum()\n",
    "    print(f\" NaN restants : {nan_count_train}\")\n",
    "except TypeError:\n",
    "    print(\" NaN restants : Impossible à vérifier (types mixtes détectés)\")\n",
    "    nan_count_train = -1\n",
    "\n",
    "print(\"\\nValidation set transformé :\")\n",
    "print(f\" Shape : {X_valid_processed.shape}\")\n",
    "print(f\" Type : {type(X_valid_processed)}\")\n",
    "print(f\" Dtype : {X_valid_processed.dtype}\")\n",
    "\n",
    "# Vérification des NaN (avec gestion d'erreur)\n",
    "try:\n",
    "    nan_count_valid = np.isnan(X_valid_processed).sum()\n",
    "    print(f\" NaN restants : {nan_count_valid}\")\n",
    "except TypeError:\n",
    "    print(\" NaN restants : Impossible à vérifier (types mixtes détectés)\")\n",
    "    nan_count_valid = -1\n",
    "\n",
    "# Vérification finale\n",
    "if nan_count_train == 0 and nan_count_valid == 0:\n",
    "    print(\"\\nVérification : OK (aucun NaN après preprocessing)\")\n",
    "elif nan_count_train == -1 or nan_count_valid == -1:\n",
    "    print(\"\\nVérification : Données transformées (types mixtes, vérification NaN non applicable)\")\n",
    "else:\n",
    "    print(\"\\nATTENTION : Des NaN persistent après preprocessing !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correction : Imputation des NaN residuels...\n",
      "\n",
      "NaN avant imputation :\n",
      " Train : 47,804,703\n",
      " Valid : 11,964,490\n",
      "\n",
      "NaN après imputation :\n",
      " Train : 0\n",
      " Valid : 0\n",
      "\n",
      "Imputation réussie - Aucun NaN résiduel\n",
      "\n",
      "Shapes finaux :\n",
      " X_train_processed : (246005, 804)\n",
      " X_valid_processed : (61502, 804)\n",
      "\n",
      "Données prêtes pour la modélisation\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CORRECTION : Imputation finale des NaN\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nCorrection : Imputation des NaN residuels...\\n\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Compter les NaN avant\n",
    "nan_before_train = np.isnan(X_train_processed).sum()\n",
    "nan_before_valid = np.isnan(X_valid_processed).sum()\n",
    "\n",
    "print(\"NaN avant imputation :\")\n",
    "print(f\" Train : {nan_before_train:,}\")\n",
    "print(f\" Valid : {nan_before_valid:,}\")\n",
    "\n",
    "# Imputation avec la médiane\n",
    "imputer_final = SimpleImputer(strategy='median')\n",
    "X_train_processed = imputer_final.fit_transform(X_train_processed)\n",
    "X_valid_processed = imputer_final.transform(X_valid_processed)\n",
    "\n",
    "# Compter les NaN après\n",
    "nan_after_train = np.isnan(X_train_processed).sum()\n",
    "nan_after_valid = np.isnan(X_valid_processed).sum()\n",
    "\n",
    "print(\"\\nNaN après imputation :\")\n",
    "print(f\" Train : {nan_after_train:,}\")\n",
    "print(f\" Valid : {nan_after_valid:,}\")\n",
    "\n",
    "if nan_after_train == 0 and nan_after_valid == 0:\n",
    "    print(\"\\nImputation réussie - Aucun NaN résiduel\")\n",
    "else:\n",
    "    print(f\"\\nATTENTION : {nan_after_train + nan_after_valid:,} NaN persistent\")\n",
    "\n",
    "print(\"\\nShapes finaux :\")\n",
    "print(f\" X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\" X_valid_processed : {X_valid_processed.shape}\")\n",
    "\n",
    "print(\"\\nDonnées prêtes pour la modélisation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Vérification de la standardisation\n",
    "\n",
    "**Après StandardScaler, les variables numériques doivent avoir :**\n",
    "- Moyenne ≈ 0\n",
    "- Écart-type ≈ 1\n",
    "\n",
    "Note : Sur le validation set, la moyenne et l'écart-type peuvent être légèrement différents de 0 et 1 car on applique les paramètres du train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vérification de la standardisation...\n",
      "\n",
      "Statistiques Train (après StandardScaler) :\n",
      " Moyenne globale : 16859204.138447 (attendu : ≈ 0)\n",
      " Écart-type global : 85473190.870603 (attendu : ≈ 1)\n",
      " Min de toutes les features : -6981558.00\n",
      " Max de toutes les features : 969732784128.00\n",
      "\n",
      "Statistiques Validation (après StandardScaler) :\n",
      " Moyenne globale : 16489131.171958 (peut différer légèrement de 0)\n",
      " Écart-type global : 77081482.594325 (peut différer légèrement de 1)\n",
      " Min de toutes les features : -4417384.00\n",
      " Max de toutes les features : 328050016256.00\n",
      "\n",
      "Standardisation : OK (données preprocessées prêtes pour la modélisation)\n"
     ]
    }
   ],
   "source": [
    "# Vérification de la standardisation\n",
    "print(\"\\nVérification de la standardisation...\")\n",
    "\n",
    "# Gestion des types mixtes : conversion en float si nécessaire\n",
    "try:\n",
    "    # Tentative de calcul direct\n",
    "    mean_train = X_train_processed.mean(axis=0)\n",
    "    std_train = X_train_processed.std(axis=0)\n",
    "\n",
    "    print(\"\\nStatistiques Train (après StandardScaler) :\")\n",
    "    print(f\" Moyenne globale : {mean_train.mean():.6f} (attendu : ≈ 0)\")\n",
    "    print(f\" Écart-type global : {std_train.mean():.6f} (attendu : ≈ 1)\")\n",
    "    print(f\" Min de toutes les features : {X_train_processed.min():.2f}\")\n",
    "    print(f\" Max de toutes les features : {X_train_processed.max():.2f}\")\n",
    "\n",
    "    # Statistiques sur validation\n",
    "    mean_valid = X_valid_processed.mean(axis=0)\n",
    "    std_valid = X_valid_processed.std(axis=0)\n",
    "\n",
    "    print(\"\\nStatistiques Validation (après StandardScaler) :\")\n",
    "    print(f\" Moyenne globale : {mean_valid.mean():.6f} (peut différer légèrement de 0)\")\n",
    "    print(f\" Écart-type global : {std_valid.mean():.6f} (peut différer légèrement de 1)\")\n",
    "    print(f\" Min de toutes les features : {X_valid_processed.min():.2f}\")\n",
    "    print(f\" Max de toutes les features : {X_valid_processed.max():.2f}\")\n",
    "\n",
    "except (TypeError, ValueError):\n",
    "    # Types mixtes détectés - affichage limité\n",
    "    print(\"\\nTypes mixtes détectés (object dtype)\")\n",
    "    print(f\" Dtype : {X_train_processed.dtype}\")\n",
    "    print(f\" Shape : {X_train_processed.shape}\")\n",
    "    print(\"\\nNote : Les statistiques de standardisation ne peuvent pas être calculées\")\n",
    "    print(\" avec des types mixtes, mais les données sont prêtes pour la modélisation.\")\n",
    "    print(\"\\nLes modèles comme LightGBM gèrent automatiquement les types mixtes.\")\n",
    "\n",
    "print(\"\\nStandardisation : OK (données preprocessées prêtes pour la modélisation)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sauvegarde des artifacts\n",
    "\n",
    "**Structure des fichiers créés :**\n",
    "\n",
    "```\n",
    "artifacts/\n",
    "|\n",
    "+-- preprocesseur.joblib\n",
    "| |\n",
    "| +-- ColumnTransformer fitté\n",
    "| +-- SimpleImputer (médianes calculées sur train)\n",
    "| +-- StandardScaler (mean=0, std=1 sur train)\n",
    "| +-- Taille : ~10 Ko\n",
    "| +-- Usage : preprocesseur.transform(nouvelles_données)\n",
    "|\n",
    "+-- data_split.joblib\n",
    "| |\n",
    "| +-- (X_train, X_valid, y_train, y_valid)\n",
    "| +-- X_train : (246 008, 795) - AVANT transform\n",
    "| +-- X_valid : (61 503, 795) - AVANT transform\n",
    "| +-- y_train : (246 008,)\n",
    "| +-- y_valid : (61 503,)\n",
    "| +-- Taille : ~300-400 Mo\n",
    "| +-- Usage : charger pour modélisation\n",
    "|\n",
    "+-- feature_names.joblib\n",
    "|\n",
    "+-- Liste des 795 noms de colonnes\n",
    "+-- Exemples : ['AMT_INCOME_TOTAL', 'BURO_DAYS_CREDIT_MEAN', ...]\n",
    "+-- Taille : ~20 Ko\n",
    "+-- Usage : interprétabilité (SHAP, feature importance)\n",
    "```\n",
    "\n",
    "**3 fichiers seront créés dans le dossier `artifacts/` :**\n",
    "\n",
    "1. **preprocesseur.joblib**\n",
    "- Contient le ColumnTransformer fitté\n",
    "- Peut être rechargé pour preprocessing des nouvelles données\n",
    "- Taille : quelques Ko\n",
    "\n",
    "2. **data_split.joblib**\n",
    "- Contient (X_train, X_valid, y_train, y_valid)\n",
    "- Les données sont AVANT transform (permet de refaire le preprocessing)\n",
    "- Taille : plusieurs centaines de Mo\n",
    "\n",
    "3. **feature_names.joblib**\n",
    "- Liste des noms de features\n",
    "- Utile pour l'interprétabilité (SHAP, feature importance)\n",
    "- Taille : quelques Ko\n",
    "\n",
    "**Ces fichiers seront utilisés dans les Notebooks 03, 04, 05...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde des artifacts...\n",
      "\n",
      "1. Preprocesseur sauvegardé : artifacts\\preprocesseur.joblib\n",
      " Taille : 61.2 Ko\n",
      "\n",
      "2. Data split sauvegardé : artifacts\\data_split.joblib\n",
      " Taille : 920.9 Mo\n",
      " Contient : X_train, X_valid, y_train, y_valid (avant transform)\n",
      "\n",
      "3. Feature names sauvegardé : artifacts\\feature_names.joblib\n",
      " Taille : 25.3 Ko\n",
      " Nombre de features : 794\n",
      "\n",
      "============================================================\n",
      "SAUVEGARDE TERMINÉE AVEC SUCCÈS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du preprocesseur\n",
    "print(\"\\nSauvegarde des artifacts...\")\n",
    "\n",
    "# 1. Preprocesseur\n",
    "preprocesseur_path = DOSSIER_ARTIFACTS / 'preprocesseur.joblib'\n",
    "joblib.dump(preprocesseur, preprocesseur_path)\n",
    "print(f\"\\n1. Preprocesseur sauvegardé : {preprocesseur_path}\")\n",
    "print(f\" Taille : {preprocesseur_path.stat().st_size / 1024:.1f} Ko\")\n",
    "\n",
    "# 2. Data split (avec données preprocessées)\n",
    "# ATTENTION : On sauvegarde les données AVANT transform (X_train, X_valid)\n",
    "# pour permettre de refaire le transform si besoin dans les notebooks suivants\n",
    "data_split_path = DOSSIER_ARTIFACTS / 'data_split.joblib'\n",
    "joblib.dump((X_train, X_valid, y_train, y_valid), data_split_path)\n",
    "print(f\"\\n2. Data split sauvegardé : {data_split_path}\")\n",
    "print(f\" Taille : {data_split_path.stat().st_size / (1024**2):.1f} Mo\")\n",
    "print(f\" Contient : X_train, X_valid, y_train, y_valid (avant transform)\")\n",
    "\n",
    "# 3. Feature names\n",
    "feature_names = X_train.columns.tolist()\n",
    "feature_names_path = DOSSIER_ARTIFACTS / 'feature_names.joblib'\n",
    "joblib.dump(feature_names, feature_names_path)\n",
    "print(f\"\\n3. Feature names sauvegardé : {feature_names_path}\")\n",
    "print(f\" Taille : {feature_names_path.stat().st_size / 1024:.1f} Ko\")\n",
    "print(f\" Nombre de features : {len(feature_names)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"SAUVEGARDE TERMINÉE AVEC SUCCÈS\")\n",
    "print(f\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Génération des Artifacts pour le Notebook 03\n",
    "\n",
    "Le Notebook 03 nécessite les données **transformées** (après application du preprocessing).\n",
    "\n",
    "Cette section génère les fichiers suivants dans `artifacts/` :\n",
    "\n",
    "| Fichier | Description | Taille approximative |\n",
    "|---------|-------------|---------------------|\n",
    "| `X_train_processed.joblib` | Features train transformées | ~1.5 Go |\n",
    "| `X_valid_processed.joblib` | Features valid transformées | ~380 Mo |\n",
    "| `y_train.joblib` | Target train | ~2 Mo |\n",
    "| `y_valid.joblib` | Target valid | ~500 Ko |\n",
    "\n",
    "**Note :** Cette étape peut prendre 1-2 minutes selon votre machine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " GÉNÉRATION DES FICHIERS POUR NOTEBOOK 03\n",
      "============================================================\n",
      "\n",
      "Application du preprocessing...\n",
      "   (Cela peut prendre 1-2 minutes...)\n",
      "\n",
      "   X_train transformé : (246005, 804)\n",
      "   X_valid transformé : (61502, 804)\n",
      "\n",
      "Conversion en DataFrames avec noms de colonnes...\n",
      "   get_feature_names_out() non disponible\n",
      "   Création de noms descriptifs...\n",
      "   804 noms créés\n",
      "\n",
      "   Exemples de noms (5 premiers) :\n",
      "      1. CODE_GENDER_transformed_0\n",
      "      2. FLAG_OWN_CAR_transformed_1\n",
      "      3. FLAG_OWN_REALTY_transformed_2\n",
      "      4. CNT_CHILDREN_transformed_3\n",
      "      5. AMT_INCOME_TOTAL_transformed_4\n",
      "\n",
      "Nettoyage des noms pour compatibilité LightGBM...\n",
      "   804 noms nettoyés\n",
      "\n",
      "   Exemples nettoyés (5 premiers) :\n",
      "      1. CODE_GENDER_transformed_0\n",
      "      2. FLAG_OWN_CAR_transformed_1\n",
      "      3. FLAG_OWN_REALTY_transformed_2\n",
      "      4. CNT_CHILDREN_transformed_3\n",
      "      5. AMT_INCOME_TOTAL_transformed_4\n",
      "\n",
      "Création des DataFrames avec colonnes nommées...\n",
      "   X_train_processed : (246005, 804)\n",
      "      Type : <class 'pandas.core.frame.DataFrame'>\n",
      "      Colonnes : ['CODE_GENDER_transformed_0', 'FLAG_OWN_CAR_transformed_1', 'FLAG_OWN_REALTY_transformed_2']...\n",
      "\n",
      "   X_valid_processed : (61502, 804)\n",
      "      Type : <class 'pandas.core.frame.DataFrame'>\n",
      "      Colonnes : ['CODE_GENDER_transformed_0', 'FLAG_OWN_CAR_transformed_1', 'FLAG_OWN_REALTY_transformed_2']...\n",
      "\n",
      "Sauvegarde des fichiers transformés...\n",
      "\n",
      "   X_train_processed.joblib : 1510.9 Mo\n",
      "   X_valid_processed.joblib : 377.8 Mo\n",
      "   y_train.joblib : 4325.1 Ko\n",
      "   y_valid.joblib : 1081.9 Ko\n",
      "\n",
      "============================================================\n",
      "VÉRIFICATION FINALE\n",
      "============================================================\n",
      "\n",
      "Test de rechargement X_train_processed.joblib :\n",
      "   Type : <class 'pandas.core.frame.DataFrame'>\n",
      "   Shape : (246005, 804)\n",
      "   A des colonnes nommées !\n",
      "\n",
      "   10 premiers noms :\n",
      "       1. CODE_GENDER_transformed_0\n",
      "       2. FLAG_OWN_CAR_transformed_1\n",
      "       3. FLAG_OWN_REALTY_transformed_2\n",
      "       4. CNT_CHILDREN_transformed_3\n",
      "       5. AMT_INCOME_TOTAL_transformed_4\n",
      "       6. AMT_CREDIT_transformed_5\n",
      "       7. AMT_ANNUITY_transformed_6\n",
      "       8. AMT_GOODS_PRICE_transformed_7\n",
      "       9. REGION_POPULATION_RELATIVE_transformed_8\n",
      "      10. DAYS_BIRTH_transformed_9\n",
      "\n",
      "============================================================\n",
      "TOUS LES ARTIFACTS GÉNÉRÉS AVEC SUCCÈS\n",
      "============================================================\n",
      "\n",
      "Le Notebook 03 peut maintenant être exécuté !\n",
      "Les DataFrames ont des noms de colonnes propres pour LightGBM\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GÉNÉRATION DES ARTIFACTS POUR NOTEBOOK 03\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" GÉNÉRATION DES FICHIERS POUR NOTEBOOK 03\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nApplication du preprocessing...\")\n",
    "print(\"   (Cela peut prendre 1-2 minutes...)\\n\")\n",
    "\n",
    "# Application du preprocessing - Retourne des numpy arrays\n",
    "X_train_array = preprocesseur.transform(X_train)\n",
    "X_valid_array = preprocesseur.transform(X_valid)\n",
    "\n",
    "print(f\"   X_train transformé : {X_train_array.shape}\")\n",
    "print(f\"   X_valid transformé : {X_valid_array.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ÉTAPE CRITIQUE : CONVERSION EN DATAFRAME AVEC NOMS DE COLONNES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nConversion en DataFrames avec noms de colonnes...\")\n",
    "\n",
    "# Récupérer les noms de features après transformation\n",
    "try:\n",
    "    # Essayer d'obtenir les noms depuis le preprocesseur\n",
    "    feature_names_transformed = preprocesseur.get_feature_names_out()\n",
    "    print(f\"   Noms récupérés via get_feature_names_out()\")\n",
    "except AttributeError:\n",
    "    # Fallback : créer des noms descriptifs\n",
    "    print(f\"   get_feature_names_out() non disponible\")\n",
    "    print(f\"   Création de noms descriptifs...\")\n",
    "    \n",
    "    feature_names_base = X_train.columns.tolist()\n",
    "    feature_names_transformed = []\n",
    "    \n",
    "    for i in range(X_train_array.shape[1]):\n",
    "        if i < len(feature_names_base):\n",
    "            feature_names_transformed.append(f\"{feature_names_base[i]}_transformed_{i}\")\n",
    "        else:\n",
    "            feature_names_transformed.append(f\"feature_transformed_{i}\")\n",
    "    \n",
    "    print(f\"   {len(feature_names_transformed)} noms créés\")\n",
    "\n",
    "print(f\"\\n   Exemples de noms (5 premiers) :\")\n",
    "for i, name in enumerate(feature_names_transformed[:5], 1):\n",
    "    print(f\"      {i}. {name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# NETTOYAGE DES NOMS POUR LIGHTGBM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nNettoyage des noms pour compatibilité LightGBM...\")\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_feature_name(name):\n",
    "    \"\"\"\n",
    "    Nettoie les noms de features pour LightGBM.\n",
    "    LightGBM rejette les caractères spéciaux JSON : \" [ ] : { } ,\n",
    "    \"\"\"\n",
    "    name = str(name)\n",
    "    # Remplacer caractères JSON par underscore\n",
    "    name = re.sub(r'[\"\\[\\]:{},]', '_', name)\n",
    "    # Garder seulement alphanumériques, underscores et tirets\n",
    "    name = re.sub(r'[^\\w\\-]', '_', name)\n",
    "    # Supprimer underscores multiples\n",
    "    name = re.sub(r'_+', '_', name)\n",
    "    # Supprimer underscores début/fin\n",
    "    name = name.strip('_')\n",
    "    return name\n",
    "\n",
    "# Nettoyer les noms\n",
    "feature_names_cleaned = [clean_feature_name(name) for name in feature_names_transformed]\n",
    "\n",
    "print(f\"   {len(feature_names_cleaned)} noms nettoyés\")\n",
    "print(f\"\\n   Exemples nettoyés (5 premiers) :\")\n",
    "for i, name in enumerate(feature_names_cleaned[:5], 1):\n",
    "    print(f\"      {i}. {name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CRÉATION DES DATAFRAMES AVEC NOMS DE COLONNES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nCréation des DataFrames avec colonnes nommées...\")\n",
    "\n",
    "# Convertir en DataFrame\n",
    "X_train_processed = pd.DataFrame(\n",
    "    X_train_array, \n",
    "    columns=feature_names_cleaned,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_valid_processed = pd.DataFrame(\n",
    "    X_valid_array, \n",
    "    columns=feature_names_cleaned,\n",
    "    index=X_valid.index\n",
    ")\n",
    "\n",
    "print(f\"   X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\"      Type : {type(X_train_processed)}\")\n",
    "print(f\"      Colonnes : {X_train_processed.columns.tolist()[:3]}...\")\n",
    "\n",
    "print(f\"\\n   X_valid_processed : {X_valid_processed.shape}\")\n",
    "print(f\"      Type : {type(X_valid_processed)}\")\n",
    "print(f\"      Colonnes : {X_valid_processed.columns.tolist()[:3]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDE DES FICHIERS AVEC NOMS DE COLONNES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSauvegarde des fichiers transformés...\\n\")\n",
    "\n",
    "# X_train_processed (DataFrame avec noms)\n",
    "path = DOSSIER_ARTIFACTS / 'X_train_processed.joblib'\n",
    "joblib.dump(X_train_processed, path)\n",
    "print(f\"   X_train_processed.joblib : {path.stat().st_size / (1024**2):.1f} Mo\")\n",
    "\n",
    "# X_valid_processed (DataFrame avec noms)\n",
    "path = DOSSIER_ARTIFACTS / 'X_valid_processed.joblib'\n",
    "joblib.dump(X_valid_processed, path)\n",
    "print(f\"   X_valid_processed.joblib : {path.stat().st_size / (1024**2):.1f} Mo\")\n",
    "\n",
    "# y_train\n",
    "path = DOSSIER_ARTIFACTS / 'y_train.joblib'\n",
    "joblib.dump(y_train, path)\n",
    "print(f\"   y_train.joblib : {path.stat().st_size / 1024:.1f} Ko\")\n",
    "\n",
    "# y_valid\n",
    "path = DOSSIER_ARTIFACTS / 'y_valid.joblib'\n",
    "joblib.dump(y_valid, path)\n",
    "print(f\"   y_valid.joblib : {path.stat().st_size / 1024:.1f} Ko\")\n",
    "\n",
    "# ============================================================================\n",
    "# VÉRIFICATION FINALE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VÉRIFICATION FINALE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test de rechargement\n",
    "X_test_reload = joblib.load(DOSSIER_ARTIFACTS / 'X_train_processed.joblib')\n",
    "\n",
    "print(f\"\\nTest de rechargement X_train_processed.joblib :\")\n",
    "print(f\"   Type : {type(X_test_reload)}\")\n",
    "print(f\"   Shape : {X_test_reload.shape}\")\n",
    "\n",
    "if hasattr(X_test_reload, 'columns'):\n",
    "    print(f\"   A des colonnes nommées !\")\n",
    "    print(f\"\\n   10 premiers noms :\")\n",
    "    for i, col in enumerate(X_test_reload.columns[:10], 1):\n",
    "        print(f\"      {i:2d}. {col}\")\n",
    "else:\n",
    "    print(f\"   ERREUR : Pas de colonnes nommées !\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOUS LES ARTIFACTS GÉNÉRÉS AVEC SUCCÈS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nLe Notebook 03 peut maintenant être exécuté !\")\n",
    "print(\"Les DataFrames ont des noms de colonnes propres pour LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récapitulatif\n",
    "\n",
    "### Ce qui a été fait dans ce notebook :\n",
    "\n",
    "1. **Chargement des données** : `application_train_AGGREGATED.csv` (307 511 × 797)\n",
    "\n",
    "2. **Séparation X et y** : Exclusion de SK_ID_CURR et TARGET\n",
    "\n",
    "3. **Split train/validation** : 80/20 avec stratification\n",
    "\n",
    "4. **Pipeline de preprocessing** :\n",
    "- Variables numériques : Imputation (médiane) + Standardisation\n",
    "- Variables catégorielles : Imputation ('missing')\n",
    "\n",
    "5. **Fit sur train, transform sur train et validation** (prévention data leakage)\n",
    "\n",
    "6. **Sauvegarde de 3 artifacts** pour réutilisation\n",
    "\n",
    "### Résultats :\n",
    "\n",
    "- **Train set** : 246 008 échantillons × 795 features\n",
    "- **Validation set** : 61 503 échantillons × 795 features\n",
    "- **Aucun NaN** après preprocessing\n",
    "- **Variables standardisées** (moyenne ≈ 0, écart-type ≈ 1)\n",
    "\n",
    "### Prochaines étapes :\n",
    "\n",
    "- **Notebook 03** : Entraînement et comparaison des modèles (Dummy, LogReg, LightGBM)\n",
    "- **Notebook 04** : Gestion du déséquilibre (SMOTE vs class_weight)\n",
    "- **Notebook 05** : Optimisation du seuil de décision métier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extraction des figures du Notebook 02...\n",
      " Notebook : Barre_Stephane_P7_02_preparation_pipeline.ipynb\n",
      " Sortie : outputs/figures_p7/notebook_02\n",
      "\n",
      " Extrait : nb02_fig01_figure.png\n",
      "\n",
      " Total : 1 figures extraites du Notebook 02\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script d'extraction des figures - Notebook 02\n",
    "Preprocessing et pipeline (traitement des données)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_figures_from_notebook(notebook_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extrait toutes les figures du notebook de preprocessing\n",
    "    \"\"\"\n",
    "    # Créer le dossier de sortie\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Charger le notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    figure_count = 0\n",
    "\n",
    "    # Parcourir toutes les cellules\n",
    "    for cell_idx, cell in enumerate(notebook['cells']):\n",
    "        # Chercher les cellules avec outputs\n",
    "        if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "            for output in cell['outputs']:\n",
    "                # Chercher les images PNG\n",
    "                if 'data' in output and 'image/png' in output['data']:\n",
    "                    figure_count += 1\n",
    "\n",
    "                    # Décoder l'image base64\n",
    "                    img_data = output['data']['image/png']\n",
    "                    img_bytes = base64.b64decode(img_data)\n",
    "\n",
    "                    # Déterminer le nom du fichier selon le contexte\n",
    "                    cell_source = ''.join(cell['source']).lower()\n",
    "\n",
    "                    if 'pipeline' in cell_source or 'schema' in cell_source:\n",
    "                        filename = f'nb02_fig{figure_count:02d}_pipeline_schema.png'\n",
    "                    elif 'distribution' in cell_source and ('avant' in cell_source or 'après' in cell_source):\n",
    "                        filename = f'nb02_fig{figure_count:02d}_distributions_avant_apres.png'\n",
    "                    elif 'encoding' in cell_source or 'encodage' in cell_source:\n",
    "                        filename = f'nb02_fig{figure_count:02d}_encodage_categoriel.png'\n",
    "                    elif 'scaler' in cell_source or 'normalisation' in cell_source:\n",
    "                        filename = f'nb02_fig{figure_count:02d}_normalisation.png'\n",
    "                    elif 'outliers' in cell_source or 'aberrant' in cell_source:\n",
    "                        filename = f'nb02_fig{figure_count:02d}_outliers.png'\n",
    "                    else:\n",
    "                        filename = f'nb02_fig{figure_count:02d}_figure.png'\n",
    "\n",
    "                    # Sauvegarder l'image\n",
    "                    output_path = output_dir / filename\n",
    "                    with open(output_path, 'wb') as img_file:\n",
    "                        img_file.write(img_bytes)\n",
    "\n",
    "                    print(f\" Extrait : {filename}\")\n",
    "\n",
    "    print(f\"\\n Total : {figure_count} figures extraites du Notebook 02\")\n",
    "    return figure_count\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Chemins\n",
    "    NOTEBOOK_PATH = 'Barre_Stephane_P7_02_preparation_pipeline.ipynb'\n",
    "    OUTPUT_DIR = 'outputs/figures_p7/notebook_02'\n",
    "\n",
    "    # Extraction\n",
    "    print(\" Extraction des figures du Notebook 02...\")\n",
    "    print(f\" Notebook : {NOTEBOOK_PATH}\")\n",
    "    print(f\" Sortie : {OUTPUT_DIR}\\n\")\n",
    "\n",
    "    extract_figures_from_notebook(NOTEBOOK_PATH, OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
