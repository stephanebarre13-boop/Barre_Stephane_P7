# Projet 7 - Implementez un modÃ¨le de scoring

[![CI Tests](https://github.com/stephanebarre13-boop/Barre_Stephane_P7/actions/workflows/main.yml/badge.svg)](https://github.com/stephanebarre13-boop/Barre_Stephane_P7/actions/workflows/main.yml)

**Auteur :** StÃ©phane BARRE
**Formation :** OpenClassrooms - Parcours Data Scientist  
**Date :** FÃ©vrier 2026

---

## ğŸ“‹ Description du projet

DÃ©veloppement d'un systÃ¨me de scoring crÃ©dit pour la sociÃ©tÃ© financiÃ¨re "PrÃªt Ã  dÃ©penser", permettant de prÃ©dire la probabilitÃ© de dÃ©faut de paiement d'un client et d'amÃ©liorer la transparence des dÃ©cisions de crÃ©dit.

### Objectifs

- Construire un modÃ¨le de machine learning pour prÃ©dire le risque de dÃ©faut
- Optimiser le seuil de dÃ©cision selon les coÃ»ts mÃ©tier (ratio 10:1)
- DÃ©velopper une API pour les prÃ©dictions en temps rÃ©el
- CrÃ©er un dashboard interactif avec explainability (SHAP)
- ImplÃ©menter un systÃ¨me de monitoring des dÃ©rives (data drift)

---

## ğŸ¯ Livrables

### 1. Notebooks d'analyse (7 notebooks)

1. **NB01 - AgrÃ©gation des tables** : Transformation des 122 features initiales en 804 features agrÃ©gÃ©es
2. **NB02 - Pipeline de prÃ©paration** : Preprocessing et feature engineering
3. **NB03 - Comparaison des modÃ¨les** : Benchmark de diffÃ©rents algorithmes
4. **NB04 - Gestion du dÃ©sÃ©quilibre** : Application de SMOTE et techniques de rÃ©Ã©chantillonnage
5. **NB05 - Optimisation du seuil** : Calibration selon les coÃ»ts mÃ©tier (FN=10, FP=1)
6. **NB06 - InterprÃ©tabilitÃ© SHAP** : Explainability globale et locale des prÃ©dictions
7. **NB07 - Monitoring data drift** : DÃ©tection des dÃ©rives avec Evidently

### 2. API FastAPI

- Endpoint de prÃ©diction
- Endpoint d'explainability (SHAP values)
- Health check et informations du modÃ¨le
- DockerisÃ© pour dÃ©ploiement

### 3. Dashboard Streamlit

- Interface pour chargÃ©s de relation client
- PrÃ©diction en temps rÃ©el avec jauge visuelle
- Graphiques SHAP interactifs
- Mapping des features vers libellÃ©s mÃ©tier
- Historique des dÃ©cisions

---

## ğŸ“ Structure du projet
```
Barre_Stephane_P7/
â”œâ”€â”€ README.md                                     # Ce fichier
â”œâ”€â”€ .gitignore                                    # Fichiers exclus de Git
â”‚
â”œâ”€â”€ Barre_Stephane_P7_01_aggregation_tables.ipynb
â”œâ”€â”€ Barre_Stephane_P7_02_preparation_pipeline.ipynb
â”œâ”€â”€ Barre_Stephane_P7_03_comparaison_modeles.ipynb
â”œâ”€â”€ Barre_Stephane_P7_04_desequilibre.ipynb
â”œâ”€â”€ Barre_Stephane_P7_05_optimisation_seuil.ipynb
â”œâ”€â”€ Barre_Stephane_P7_06_interpretabilite_shap.ipynb
â”œâ”€â”€ Barre_Stephane_P7_07_data_drift.ipynb
â”‚
â”œâ”€â”€ api/                                          # API FastAPI
â”‚   â”œâ”€â”€ main.py                                   # Code principal de l'API
â”‚   â”œâ”€â”€ requirements.txt                          # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile                                # Configuration Docker
â”‚
â”œâ”€â”€ dashboard/                                    # Dashboard Streamlit
â”‚   â”œâ”€â”€ app.py                                    # Application Streamlit
â”‚   â”œâ”€â”€ requirements.txt                          # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile                                # Configuration Docker
â”‚
â”œâ”€â”€ docs/                                         # Documentation
â”‚   â”œâ”€â”€ DATA_STRUCTURE.md                         # Description des donnÃ©es
â”‚   â””â”€â”€ database_schema.png                       # SchÃ©ma de la base
â”‚
â”œâ”€â”€ reports/                                      # Rapports gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ .gitkeep                                  # Maintient le dossier dans Git
â”‚
â”œâ”€â”€ scripts/                                      # Scripts utilitaires
â”‚   â””â”€â”€ .gitkeep                                  # Maintient le dossier dans Git
â”‚
â””â”€â”€ test_samples_backup/                          # Ã‰chantillons de test
    â”œâ”€â”€ batch_clients.json                        # Batch de clients
    â”œâ”€â”€ client_high_risk.json                     # Client Ã  haut risque
    â”œâ”€â”€ client_low_risk.json                      # Client Ã  faible risque
    â”œâ”€â”€ client_mixed.json                         # Client mixte
    â”œâ”€â”€ client_zeros.json                         # Client avec valeurs nulles
    â””â”€â”€ README.md                                 # Documentation des Ã©chantillons
```

---

## ğŸš€ Installation et utilisation

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Git

### Installation

**1. Cloner le repository**
```bash
git clone https://github.com/stephanebarre13-boop/Barre_Stephane_P7.git
cd Barre_Stephane_P7
```

**2. TÃ©lÃ©charger les donnÃ©es**

Les donnÃ©es sources proviennent du challenge Kaggle [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/data).

TÃ©lÃ©charger et placer les fichiers CSV dans un dossier `/data/` :
- `application_train.csv`
- `application_test.csv`
- `bureau.csv`
- `bureau_balance.csv`
- `credit_card_balance.csv`
- `installments_payments.csv`
- `POS_CASH_balance.csv`
- `previous_application.csv`

**3. GÃ©nÃ©rer les modÃ¨les**

ExÃ©cuter les notebooks dans l'ordre (01 Ã  05) pour gÃ©nÃ©rer les artifacts dans `/artifacts/`.

---

### Lancement de l'API
```bash
cd api
pip install -r requirements.txt
uvicorn main:app --reload
```

L'API sera accessible sur `http://localhost:8000`

Documentation interactive : `http://localhost:8000/docs`

---

### Lancement du dashboard
```bash
cd dashboard
pip install -r requirements.txt
streamlit run app.py
```

Le dashboard sera accessible sur `http://localhost:8501`

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Machine Learning & Data Science
- **pandas** : Manipulation de donnÃ©es
- **numpy** : Calculs numÃ©riques
- **scikit-learn** : Preprocessing et mÃ©triques
- **LightGBM** : Algorithme de gradient boosting
- **imbalanced-learn** : Gestion du dÃ©sÃ©quilibre (SMOTE)
- **SHAP** : Explainability des prÃ©dictions

### Backend & API
- **FastAPI** : Framework API REST
- **Pydantic** : Validation des donnÃ©es
- **uvicorn** : Serveur ASGI
- **joblib** : SÃ©rialisation des modÃ¨les

### Frontend
- **Streamlit** : Dashboard interactif
- **Plotly** : Visualisations interactives

### Monitoring & DevOps
- **Evidently** : DÃ©tection de data drift
- **Docker** : Conteneurisation
- **pytest** : Tests unitaires (si applicable)

---

## ğŸ“Š RÃ©sultats et performances

### ModÃ¨le final
- **Algorithme** : LightGBM Classifier
- **Features** : 804 (aprÃ¨s agrÃ©gation de 7 tables)
- **Seuil optimal** : 0.370 (optimisÃ© selon ratio coÃ»t 10:1)

### MÃ©thodologie
- **Gestion dÃ©sÃ©quilibre** : SMOTE + ajustement des poids de classe
- **Optimisation** : Minimisation du coÃ»t mÃ©tier (FN coÃ»te 10x plus que FP)
- **Explainability** : SHAP values pour chaque prÃ©diction

### Monitoring
- **Data drift** : Monitoring avec Evidently pour dÃ©tecter les dÃ©rives
- **Rapports** : GÃ©nÃ©ration automatique de rapports HTML

---

## ğŸ“ Notes importantes

### DonnÃ©es exclues du repository

Les fichiers suivants sont exclus du repository Git (voir `.gitignore`) :
- `/data/` : DonnÃ©es sources (plusieurs Go)
- `/artifacts/` : ModÃ¨les entraÃ®nÃ©s (peuvent Ãªtre rÃ©gÃ©nÃ©rÃ©s)

Ces exclusions respectent les bonnes pratiques Git (pas de fichiers volumineux).

### ReproductibilitÃ©

Le projet est entiÃ¨rement reproductible :
1. TÃ©lÃ©charger les donnÃ©es depuis Kaggle
2. ExÃ©cuter les notebooks 01 Ã  07 dans l'ordre
3. Les artifacts seront gÃ©nÃ©rÃ©s automatiquement

---

## ğŸ“ CompÃ©tences dÃ©veloppÃ©es

- DÃ©veloppement d'un modÃ¨le de scoring avec gestion du dÃ©sÃ©quilibre
- Optimisation selon des contraintes mÃ©tier
- DÃ©ploiement d'une API de prÃ©diction
- CrÃ©ation d'un dashboard avec explainability
- Monitoring des performances en production
- Conteneurisation avec Docker

---

## ğŸ“§ Contact

**StÃ©phane BARRE**  
Ã‰tudiant - OpenClassrooms Data Scientist  
GitHub : [stephanebarre13-boop](https://github.com/stephanebarre13-boop)

---

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans le cadre de la formation OpenClassrooms Data Scientist.
