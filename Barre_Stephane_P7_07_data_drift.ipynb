{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Projet 7 PREMIUM - Étape 6 : Data Drift et Monitoring\n",
    "\n",
    "**Objectif** : Détecter le data drift avec Evidently\n",
    "\n",
    "## Contenu\n",
    "1. Simuler données production\n",
    "2. Rapport Evidently (drift detection)\n",
    "3. Analyse drift par feature\n",
    "4. Recommandations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, DataQualityPreset\n",
    "import joblib\n",
    "\n",
    "print(' Imports OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger données\n",
    "DOSSIER_ARTIFACTS = Path('./artifacts')\n",
    "X_train, X_valid, y_train, y_valid = joblib.load(DOSSIER_ARTIFACTS / 'data_split.joblib')\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Valid: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préparer données de référence et production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Référence = Train\n",
    "df_reference = X_train.copy()\n",
    "df_reference['TARGET'] = y_train.values\n",
    "\n",
    "# Production = Valid (simulé)\n",
    "df_production = X_valid.copy()\n",
    "df_production['TARGET'] = y_valid.values\n",
    "\n",
    "# Pour simuler un drift, on peut modifier quelques colonnes\n",
    "# (Optionnel : décommenter pour tester)\n",
    "# df_production['AMT_CREDIT'] = df_production['AMT_CREDIT'] * 1.2  # Augmentation 20%\n",
    "# df_production['DAYS_BIRTH'] = df_production['DAYS_BIRTH'] + 1000  # Clients plus jeunes\n",
    "\n",
    "print(f\"\\nRéférence (train): {len(df_reference)} clients\")\n",
    "print(f\"Production (valid): {len(df_production)} clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir colonnes numériques vs catégorielles\n",
    "colonnes_num = df_reference.select_dtypes(include=['number']).columns.tolist()\n",
    "colonnes_cat = df_reference.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "# Retirer TARGET\n",
    "if 'TARGET' in colonnes_num:\n",
    "    colonnes_num.remove('TARGET')\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    target='TARGET',\n",
    "    numerical_features=colonnes_num[:30],  # Limiter pour rapidité\n",
    "    categorical_features=colonnes_cat[:10]\n",
    ")\n",
    "\n",
    "print(f\" Colonnes numériques: {len(column_mapping.numerical_features)}\")\n",
    "print(f\" Colonnes catégorielles: {len(column_mapping.categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Générer rapport Evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer rapport\n",
    "print(\" Génération rapport Evidently...\")\n",
    "\n",
    "report = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "    DataQualityPreset()\n",
    "])\n",
    "\n",
    "report.run(\n",
    "    reference_data=df_reference,\n",
    "    current_data=df_production,\n",
    "    column_mapping=column_mapping\n",
    ")\n",
    "\n",
    "# Sauvegarder HTML\n",
    "DOSSIER_REPORTS = Path('../reports')\n",
    "DOSSIER_REPORTS.mkdir(exist_ok=True)\n",
    "\n",
    "report.save_html(str(DOSSIER_REPORTS / 'data_drift_report.html'))\n",
    "\n",
    "print(\"\\n Rapport sauvegardé: reports/data_drift_report.html\")\n",
    "print(\" Ouvrir ce fichier dans un navigateur pour voir le rapport complet\")\n",
    "print(\" À capturer pour PowerPoint Slide 9\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyser résultats drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire résultats (simplifié)\n",
    "try:\n",
    "    results = report.as_dict()\n",
    "    \n",
    "    # Statistiques drift\n",
    "    drift_metrics = results['metrics'][0]['result']\n",
    "    \n",
    "    dataset_drift = drift_metrics.get('dataset_drift', False)\n",
    "    drift_share = drift_metrics.get('drift_share', 0)\n",
    "    n_features = drift_metrics.get('number_of_columns', 0)\n",
    "    n_drifted = drift_metrics.get('number_of_drifted_columns', 0)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" RÉSULTATS DATA DRIFT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nDrift dataset détecté: {' OUI' if dataset_drift else ' NON'}\")\n",
    "    print(f\"Features analysées: {n_features}\")\n",
    "    print(f\"Features avec drift: {n_drifted}\")\n",
    "    print(f\"Proportion drift: {drift_share:.1%}\")\n",
    "    \n",
    "    # Seuil alerte\n",
    "    SEUIL_ALERTE = 0.30  # 30% features driftées\n",
    "    \n",
    "    if drift_share > SEUIL_ALERTE:\n",
    "        print(f\"\\n ALERTE: Drift > {SEUIL_ALERTE:.0%}\")\n",
    "        print(\"   Action recommandée: Ré-entraînement du modèle\")\n",
    "    else:\n",
    "        print(f\"\\n OK: Drift < {SEUIL_ALERTE:.0%}\")\n",
    "        print(\"   Modèle stable, pas de ré-entraînement nécessaire\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Erreur extraction résultats: {e}\")\n",
    "    print(\"Consulter le rapport HTML pour plus de détails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommandations monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" RECOMMANDATIONS MONITORING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Fréquence surveillance:\")\n",
    "print(\"   - Hebdomadaire: Vérifier rapport drift\")\n",
    "print(\"   - Mensuel: Rapport complet + AUC validation\")\n",
    "print(\"   - Trimestriel: Ré-entraînement si drift > 30%\")\n",
    "\n",
    "print(\"\\n2. Indicateurs à suivre:\")\n",
    "print(\"   - % features driftées (seuil: 30%)\")\n",
    "print(\"   - AUC validation (seuil: -5% vs train)\")\n",
    "print(\"   - Distribution TARGET (% défauts)\")\n",
    "print(\"   - Temps réponse API (<200ms)\")\n",
    "\n",
    "print(\"\\n3. Actions correctives:\")\n",
    "print(\"   - Si drift modéré (20-30%): Valider manuellement quelques prédictions\")\n",
    "print(\"   - Si drift fort (>30%): Ré-entraînement avec nouvelles données\")\n",
    "print(\"   - Si AUC baisse >5%: Investiguer features driftées\")\n",
    "\n",
    "print(\"\\n4. Outils:\")\n",
    "print(\"   - Evidently: Génération rapports drift\")\n",
    "print(\"   - MLflow: Tracking expériences ré-entraînement\")\n",
    "print(\"   - Prometheus/Grafana: Monitoring production (optionnel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation simple drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer distributions pour une feature clé\n",
    "feature_exemple = 'AMT_CREDIT'\n",
    "\n",
    "if feature_exemple in df_reference.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Distribution référence\n",
    "    axes[0].hist(df_reference[feature_exemple].dropna(), bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0].set_title(f'{feature_exemple} - Référence (Train)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Valeur', fontsize=12)\n",
    "    axes[0].set_ylabel('Fréquence', fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Distribution production\n",
    "    axes[1].hist(df_production[feature_exemple].dropna(), bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "    axes[1].set_title(f'{feature_exemple} - Production (Valid)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Valeur', fontsize=12)\n",
    "    axes[1].set_ylabel('Fréquence', fontsize=12)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Comparaison distributions - {feature_exemple}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    DOSSIER_FIGURES = Path('../figures')\n",
    "    plt.savefig(DOSSIER_FIGURES / f'drift_distribution_{feature_exemple}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'\\n Figure sauvegardée: figures/drift_distribution_{feature_exemple}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Résumé\n",
    "\n",
    "-  Rapport Evidently généré (HTML)\n",
    "-  Data drift analysé\n",
    "-  Recommandations monitoring définies\n",
    "-  Seuils d'alerte configurés (30% features)\n",
    "-  Plan de ré-entraînement établi\n",
    "\n",
    "**Fichiers générés** :\n",
    "- reports/data_drift_report.html (à ouvrir dans navigateur)\n",
    "- figures/drift_distribution_*.png\n",
    "\n",
    "---\n",
    "\n",
    "##  PROJET TERMINÉ !\n",
    "\n",
    "Tous les notebooks sont complétés. Prochaines étapes :\n",
    "1. Tester l'API (voir README.md)\n",
    "2. Tester le Dashboard\n",
    "3. Insérer les figures dans PowerPoint\n",
    "4. Préparer la soutenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script d'extraction des figures - Notebook 07\n",
    "Data drift monitoring avec Evidently\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_figures_from_notebook(notebook_path, output_dir):\n",
    "    \"\"\"\n",
    "    Extrait toutes les figures du notebook de data drift\n",
    "    \"\"\"\n",
    "    # Créer le dossier de sortie\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Charger le notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "    \n",
    "    figure_count = 0\n",
    "    \n",
    "    # Parcourir toutes les cellules\n",
    "    for cell_idx, cell in enumerate(notebook['cells']):\n",
    "        # Chercher les cellules avec outputs\n",
    "        if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "            for output in cell['outputs']:\n",
    "                # Chercher les images PNG\n",
    "                if 'data' in output and 'image/png' in output['data']:\n",
    "                    figure_count += 1\n",
    "                    \n",
    "                    # Décoder l'image base64\n",
    "                    img_data = output['data']['image/png']\n",
    "                    img_bytes = base64.b64decode(img_data)\n",
    "                    \n",
    "                    # Déterminer le nom du fichier selon le contexte\n",
    "                    cell_source = ''.join(cell['source']).lower()\n",
    "                    \n",
    "                    if 'evidently' in cell_source or 'report' in cell_source:\n",
    "                        filename = f'nb07_fig{figure_count:02d}_evidently_report.png'\n",
    "                    elif 'drift' in cell_source and 'top' in cell_source:\n",
    "                        filename = f'nb07_fig{figure_count:02d}_top_drifted_features.png'\n",
    "                    elif 'distribution' in cell_source or 'shift' in cell_source:\n",
    "                        filename = f'nb07_fig{figure_count:02d}_distribution_shift.png'\n",
    "                    elif 'kolmogorov' in cell_source or 'statistical' in cell_source:\n",
    "                        filename = f'nb07_fig{figure_count:02d}_statistical_tests.png'\n",
    "                    else:\n",
    "                        filename = f'nb07_fig{figure_count:02d}_figure.png'\n",
    "                    \n",
    "                    # Sauvegarder l'image\n",
    "                    output_path = output_dir / filename\n",
    "                    with open(output_path, 'wb') as img_file:\n",
    "                        img_file.write(img_bytes)\n",
    "                    \n",
    "                    print(f\" Extrait : {filename}\")\n",
    "    \n",
    "    print(f\"\\n Total : {figure_count} figures extraites du Notebook 07\")\n",
    "    return figure_count\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Chemins\n",
    "    NOTEBOOK_PATH = 'Barre_Stephane_P7_07_data_drift.ipynb'\n",
    "    OUTPUT_DIR = 'outputs/figures_p7/notebook_07'\n",
    "    \n",
    "    # Extraction\n",
    "    print(\" Extraction des figures du Notebook 07...\")\n",
    "    print(f\" Notebook : {NOTEBOOK_PATH}\")\n",
    "    print(f\" Sortie : {OUTPUT_DIR}\\n\")\n",
    "    \n",
    "    extract_figures_from_notebook(NOTEBOOK_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
