{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03 : Comparaison de 5 Modèles de Machine Learning\n",
    "\n",
    "## Contexte\n",
    "\n",
    "**Objectif :** Comparer **5 modèles** de machine learning et sélectionner le meilleur pour la prédiction de défaut de paiement.\n",
    "\n",
    "**Métrique principale : AUC (Area Under the ROC Curve)**\n",
    "\n",
    "L'AUC mesure la capacité du modèle à discriminer entre les classes 0 (remboursement) et 1 (défaut). Plus l'AUC est proche de 1, meilleur est le modèle.\n",
    "\n",
    "**Pourquoi pas l'accuracy ?**\n",
    "- Dataset déséquilibré (92% classe 0, 8% classe 1)\n",
    "- Un modèle prédisant toujours 0 aurait 92% d'accuracy mais AUC = 0.5\n",
    "- L'AUC évalue la capacité à bien ordonner les prédictions, pas juste la précision\n",
    "\n",
    "**Métrique métier : Coût = 10×FN + 1×FP**\n",
    "- FN (Faux Négatif) : Prêter à un client qui fera défaut → Coût élevé (10€)\n",
    "- FP (Faux Positif) : Refuser un bon client → Coût faible (1€)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles évalués (Conforme recommandations mentor)\n",
    "\n",
    "### 1. DummyClassifier (Baseline naïve)\n",
    "**Description :** Prédit toujours la classe majoritaire (0 = remboursement)\n",
    "\n",
    "**Utilité :** Établir un plancher de performance. Tout modèle doit faire mieux que le Dummy.\n",
    "\n",
    "**Performance attendue :**\n",
    "- AUC : ~0.50 (équivalent à un tirage aléatoire)\n",
    "- Coût métier : ~32,000€ (le plus élevé)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Régression Logistique\n",
    "**Description :** Modèle linéaire avec fonction sigmoïde\n",
    "\n",
    "**Avantages :**\n",
    "- Simple et interprétable (coefficients)\n",
    "- Rapide à entraîner\n",
    "- Robuste, peu sujet à l'overfitting\n",
    "\n",
    "**Limites :**\n",
    "- Assume une relation linéaire\n",
    "- Ne capture pas les interactions complexes\n",
    "\n",
    "**Performance attendue :**\n",
    "- AUC : 0.54-0.56\n",
    "- Coût métier : ~29,000€\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Random Forest\n",
    "**Description :** Ensemble de decision trees entraînés sur des sous-échantillons\n",
    "\n",
    "**Avantages :**\n",
    "- Capture les interactions non-linéaires\n",
    "- Robuste au surapprentissage (grâce au bagging)\n",
    "- Gère bien les features corrélées\n",
    "\n",
    "**Paramètres clés :**\n",
    "- `n_estimators` : Nombre d'arbres (100-500)\n",
    "- `max_depth` : Profondeur maximale\n",
    "- `min_samples_split` : Échantillons minimum pour split\n",
    "\n",
    "**Performance attendue :**\n",
    "- AUC : 0.74-0.76\n",
    "- Coût métier : ~27,000€\n",
    "\n",
    "---\n",
    "\n",
    "### 4. XGBoost (Extreme Gradient Boosting)\n",
    "**Description :** Gradient boosting optimisé avec régularisation\n",
    "\n",
    "**Avantages :**\n",
    "- Très performant sur données tabulaires\n",
    "- Régularisation L1/L2 intégrée\n",
    "- Gère nativement les valeurs manquantes\n",
    "- Parallélisation efficace\n",
    "\n",
    "**Paramètres clés :**\n",
    "- `n_estimators` : Nombre d'arbres\n",
    "- `max_depth` : Profondeur (3-10)\n",
    "- `learning_rate` : Taux d'apprentissage (0.01-0.1)\n",
    "- `colsample_bytree` : Fraction de features par arbre\n",
    "\n",
    "**Performance attendue :**\n",
    "- AUC : 0.77-0.79\n",
    "- Coût métier : ~26,000€\n",
    "\n",
    "---\n",
    "\n",
    "### 5. LightGBM (Gradient Boosting)\n",
    "**Description :** Gradient boosting optimisé pour rapidité et efficacité mémoire\n",
    "\n",
    "**Avantages :**\n",
    "- Plus rapide que XGBoost\n",
    "- Très efficace en mémoire\n",
    "- Gère nativement les valeurs manquantes\n",
    "- Excellentes performances sur gros datasets\n",
    "\n",
    "**Paramètres clés :**\n",
    "- `n_estimators` : Nombre d'arbres\n",
    "- `max_depth` : Profondeur maximale\n",
    "- `learning_rate` : Taux d'apprentissage\n",
    "- `num_leaves` : Nombre de feuilles par arbre\n",
    "\n",
    "**Performance attendue :**\n",
    "- AUC : 0.77-0.80 (meilleur attendu)\n",
    "- Coût métier : ~25,000€ (le plus bas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (\n",
    "roc_auc_score,\n",
    "roc_curve,\n",
    "confusion_matrix,\n",
    "recall_score,\n",
    "precision_score,\n",
    "f1_score\n",
    ")\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\" Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données Preprocessed\n",
    "\n",
    "Chargement direct des données déjà preprocessed du Notebook 02 :\n",
    "- `X_train_processed.joblib` : Données train transformées (804 features)\n",
    "- `X_valid_processed.joblib` : Données validation transformées (804 features)\n",
    "- `y_train.joblib` : Labels train\n",
    "- `y_valid.joblib` : Labels validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHARGEMENT DES DONNÉES TRANSFORMÉES (déjà prêtes depuis Notebook 02)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nChargement des données depuis Notebook 02...\\n\")\n",
    "\n",
    "# Chargement des données DÉJÀ transformées (pas besoin de re-transformer)\n",
    "X_train_processed = joblib.load('./artifacts/X_train_processed.joblib')\n",
    "X_valid_processed = joblib.load('./artifacts/X_valid_processed.joblib')\n",
    "y_train = joblib.load('./artifacts/y_train.joblib')\n",
    "y_valid = joblib.load('./artifacts/y_valid.joblib')\n",
    "\n",
    "print(f\"   X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\"   X_valid_processed : {X_valid_processed.shape}\")\n",
    "print(f\"   y_train : {y_train.shape}\")\n",
    "print(f\"   y_valid : {y_valid.shape}\")\n",
    "\n",
    "# Vérifier le type\n",
    "print(f\"\\n   Type X_train_processed : {type(X_train_processed)}\")\n",
    "\n",
    "if hasattr(X_train_processed, 'columns'):\n",
    "    print(f\"   DataFrame avec colonnes nommées\")\n",
    "    print(f\"   Colonnes (5 premières) : {X_train_processed.columns.tolist()[:5]}\")\n",
    "else:\n",
    "    print(f\"   ATTENTION : Type array sans noms de colonnes !\")\n",
    "\n",
    "# Vérifier les NaN\n",
    "if hasattr(X_train_processed, 'isna'):\n",
    "    # DataFrame\n",
    "    nan_count = X_train_processed.isna().sum().sum()\n",
    "else:\n",
    "    # Array\n",
    "    nan_count = np.isnan(X_train_processed).sum()\n",
    "\n",
    "print(f\"\\n   NaN dans X_train_processed : {nan_count}\")\n",
    "\n",
    "print(\"\\nDonnées prêtes pour la modélisation !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification et Nettoyage des NaN\n",
    "\n",
    "**Problème potentiel** : Les artifacts peuvent contenir des NaN résiduels.\n",
    "\n",
    "**Solution** : Vérifier et nettoyer avec `np.nan_to_num()` si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les NaN\n",
    "nan_train = np.isnan(X_train_processed).sum().sum()\n",
    "nan_valid = np.isnan(X_valid_processed).sum().sum()\n",
    "\n",
    "print(\"Vérification des NaN :\")\n",
    "print(f\"X_train_processed : {nan_train:,} NaN\")\n",
    "print(f\"X_valid_processed : {nan_valid:,} NaN\")\n",
    "\n",
    "# Nettoyer si nécessaire\n",
    "if nan_train > 0 or nan_valid > 0:\n",
    "    print(\"\\nATTENTION : NaN détectés !\")\n",
    "    print(\"Nettoyage avec np.nan_to_num() (remplace NaN par 0)...\")\n",
    "\n",
    "    X_train_processed = np.nan_to_num(X_train_processed, nan=0.0, copy=False)\n",
    "    X_valid_processed = np.nan_to_num(X_valid_processed, nan=0.0, copy=False)\n",
    "\n",
    "    # Vérification finale\n",
    "    nan_train_after = np.isnan(X_train_processed).sum().sum()\n",
    "    nan_valid_after = np.isnan(X_valid_processed).sum().sum()\n",
    "\n",
    "    print(\"Nettoyage terminé :\")\n",
    "    print(f\"X_train_processed : {nan_train_after:,} NaN\")\n",
    "    print(f\"X_valid_processed : {nan_valid_after:,} NaN\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nPas de NaN détectés - Données prêtes !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les artifacts du Notebook 02\n",
    "X_train_processed = joblib.load('./artifacts/X_train_processed.joblib')\n",
    "X_valid_processed = joblib.load('./artifacts/X_valid_processed.joblib')\n",
    "y_train = joblib.load('./artifacts/y_train.joblib')\n",
    "y_valid = joblib.load('./artifacts/y_valid.joblib')\n",
    "\n",
    "print(\" Données chargées\")\n",
    "print(f\" X_train shape : {X_train_processed.shape}\")\n",
    "print(f\" X_valid shape : {X_valid_processed.shape}\")\n",
    "print(f\" y_train shape : {y_train.shape}\")\n",
    "print(f\" y_valid shape : {y_valid.shape}\")\n",
    "\n",
    "# Vérifier le déséquilibre\n",
    "print(f\"\\n Déséquilibre :\")\n",
    "print(f\" Classe 0 : {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\" Classe 1 : {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CORRECTION : Imputation finale des NaN\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nCorrection : Imputation des NaN residuels...\\n\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Compter les NaN avant (total)\n",
    "nan_before_train = np.isnan(X_train_processed).sum().sum()\n",
    "nan_before_valid = np.isnan(X_valid_processed).sum().sum()\n",
    "\n",
    "print(\"NaN avant imputation :\")\n",
    "print(f\" Train : {nan_before_train:,}\")\n",
    "print(f\" Valid : {nan_before_valid:,}\")\n",
    "\n",
    "# Imputation avec la mediane\n",
    "imputer_final = SimpleImputer(strategy='median')\n",
    "X_train_processed = imputer_final.fit_transform(X_train_processed)\n",
    "X_valid_processed = imputer_final.transform(X_valid_processed)\n",
    "\n",
    "# Compter les NaN après (total)\n",
    "nan_after_train = np.isnan(X_train_processed).sum().sum()\n",
    "nan_after_valid = np.isnan(X_valid_processed).sum().sum()\n",
    "\n",
    "print(\"\\nNaN apres imputation :\")\n",
    "print(f\" Train : {nan_after_train:,}\")\n",
    "print(f\" Valid : {nan_after_valid:,}\")\n",
    "\n",
    "if nan_after_train == 0 and nan_after_valid == 0:\n",
    "    print(\"\\nImputation reussie - Aucun NaN residuel\")\n",
    "else:\n",
    "    print(f\"\\nATTENTION : {nan_after_train + nan_after_valid:,} NaN persistent\")\n",
    "\n",
    "print(\"\\nShapes finaux :\")\n",
    "print(f\" X_train_processed : {X_train_processed.shape}\")\n",
    "print(f\" X_valid_processed : {X_valid_processed.shape}\")\n",
    "\n",
    "print(\"\\nDonnees pretes pour la modelisation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 1 : DummyClassifier (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 1 : DUMMYCLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entraînement\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "start = time.time()\n",
    "dummy.fit(X_train_processed, y_train)\n",
    "time_dummy = time.time() - start\n",
    "\n",
    "# Prédictions\n",
    "y_pred_dummy = dummy.predict(X_valid_processed)\n",
    "y_proba_dummy = dummy.predict_proba(X_valid_processed)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "auc_dummy = roc_auc_score(y_valid, y_proba_dummy)\n",
    "recall_dummy = recall_score(y_valid, y_pred_dummy)\n",
    "precision_dummy = precision_score(y_valid, y_pred_dummy, zero_division=0)\n",
    "f1_dummy = f1_score(y_valid, y_pred_dummy, zero_division=0)\n",
    "\n",
    "# Coût métier\n",
    "cm_dummy = confusion_matrix(y_valid, y_pred_dummy)\n",
    "tn, fp, fn, tp = cm_dummy.ravel()\n",
    "cout_dummy = (fn * 10) + (fp * 1)\n",
    "\n",
    "print(f\"\\n RÉSULTATS :\")\n",
    "print(f\" Temps : {time_dummy:.2f}s\")\n",
    "print(f\" AUC : {auc_dummy:.4f}\")\n",
    "print(f\" Recall : {recall_dummy:.4f}\")\n",
    "print(f\" Precision : {precision_dummy:.4f}\")\n",
    "print(f\" F1-Score : {f1_dummy:.4f}\")\n",
    "print(f\" Coût métier (10×FN + 1×FP) : {cout_dummy:,}€\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 2 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 2 : LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entraînement\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "start = time.time()\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "time_logreg = time.time() - start\n",
    "\n",
    "# Prédictions\n",
    "y_pred_logreg = logreg.predict(X_valid_processed)\n",
    "y_proba_logreg = logreg.predict_proba(X_valid_processed)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "auc_logreg = roc_auc_score(y_valid, y_proba_logreg)\n",
    "recall_logreg = recall_score(y_valid, y_pred_logreg)\n",
    "precision_logreg = precision_score(y_valid, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_valid, y_pred_logreg)\n",
    "\n",
    "# Coût métier\n",
    "cm_logreg = confusion_matrix(y_valid, y_pred_logreg)\n",
    "tn, fp, fn, tp = cm_logreg.ravel()\n",
    "cout_logreg = (fn * 10) + (fp * 1)\n",
    "\n",
    "print(f\"\\n RÉSULTATS :\")\n",
    "print(f\" Temps : {time_logreg:.2f}s\")\n",
    "print(f\" AUC : {auc_logreg:.4f}\")\n",
    "print(f\" Recall : {recall_logreg:.4f}\")\n",
    "print(f\" Precision : {precision_logreg:.4f}\")\n",
    "print(f\" F1-Score : {f1_logreg:.4f}\")\n",
    "print(f\" Coût métier (10×FN + 1×FP) : {cout_logreg:,}€\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 3 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 3 : RANDOM FOREST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entraînement\n",
    "rf = RandomForestClassifier(\n",
    "n_estimators=200,\n",
    "max_depth=10,\n",
    "min_samples_split=10,\n",
    "random_state=42,\n",
    "n_jobs=-1,\n",
    "verbose=0\n",
    ")\n",
    "start = time.time()\n",
    "rf.fit(X_train_processed, y_train)\n",
    "time_rf = time.time() - start\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf = rf.predict(X_valid_processed)\n",
    "y_proba_rf = rf.predict_proba(X_valid_processed)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "auc_rf = roc_auc_score(y_valid, y_proba_rf)\n",
    "recall_rf = recall_score(y_valid, y_pred_rf)\n",
    "precision_rf = precision_score(y_valid, y_pred_rf)\n",
    "f1_rf = f1_score(y_valid, y_pred_rf)\n",
    "\n",
    "# Coût métier\n",
    "cm_rf = confusion_matrix(y_valid, y_pred_rf)\n",
    "tn, fp, fn, tp = cm_rf.ravel()\n",
    "cout_rf = (fn * 10) + (fp * 1)\n",
    "\n",
    "print(f\"\\n RÉSULTATS :\")\n",
    "print(f\" Temps : {time_rf:.2f}s\")\n",
    "print(f\" AUC : {auc_rf:.4f}\")\n",
    "print(f\" Recall : {recall_rf:.4f}\")\n",
    "print(f\" Precision : {precision_rf:.4f}\")\n",
    "print(f\" F1-Score : {f1_rf:.4f}\")\n",
    "print(f\" Coût métier (10×FN + 1×FP) : {cout_rf:,}€\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 4 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 4 : XGBOOST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entraînement\n",
    "xgb = XGBClassifier(\n",
    "n_estimators=200,\n",
    "max_depth=7,\n",
    "learning_rate=0.05,\n",
    "random_state=42,\n",
    "n_jobs=-1,\n",
    "verbosity=0\n",
    ")\n",
    "start = time.time()\n",
    "xgb.fit(X_train_processed, y_train)\n",
    "time_xgb = time.time() - start\n",
    "\n",
    "# Prédictions\n",
    "y_pred_xgb = xgb.predict(X_valid_processed)\n",
    "y_proba_xgb = xgb.predict_proba(X_valid_processed)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "auc_xgb = roc_auc_score(y_valid, y_proba_xgb)\n",
    "recall_xgb = recall_score(y_valid, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_valid, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_valid, y_pred_xgb)\n",
    "\n",
    "# Coût métier\n",
    "cm_xgb = confusion_matrix(y_valid, y_pred_xgb)\n",
    "tn, fp, fn, tp = cm_xgb.ravel()\n",
    "cout_xgb = (fn * 10) + (fp * 1)\n",
    "\n",
    "print(f\"\\n RÉSULTATS :\")\n",
    "print(f\" Temps : {time_xgb:.2f}s\")\n",
    "print(f\" AUC : {auc_xgb:.4f}\")\n",
    "print(f\" Recall : {recall_xgb:.4f}\")\n",
    "print(f\" Precision : {precision_xgb:.4f}\")\n",
    "print(f\" F1-Score : {f1_xgb:.4f}\")\n",
    "print(f\" Coût métier (10×FN + 1×FP) : {cout_xgb:,}€\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle 5 : LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODÈLE 5 : LIGHTGBM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entraînement\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "n_estimators=500,\n",
    "max_depth=7,\n",
    "learning_rate=0.05,\n",
    "random_state=42,\n",
    "n_jobs=-1,\n",
    "verbose=-1\n",
    ")\n",
    "start = time.time()\n",
    "lgbm.fit(X_train_processed, y_train)\n",
    "time_lgbm = time.time() - start\n",
    "\n",
    "# Prédictions\n",
    "y_pred_lgbm = lgbm.predict(X_valid_processed)\n",
    "y_proba_lgbm = lgbm.predict_proba(X_valid_processed)[:, 1]\n",
    "\n",
    "# Métriques\n",
    "auc_lgbm = roc_auc_score(y_valid, y_proba_lgbm)\n",
    "recall_lgbm = recall_score(y_valid, y_pred_lgbm)\n",
    "precision_lgbm = precision_score(y_valid, y_pred_lgbm)\n",
    "f1_lgbm = f1_score(y_valid, y_pred_lgbm)\n",
    "\n",
    "# Coût métier\n",
    "cm_lgbm = confusion_matrix(y_valid, y_pred_lgbm)\n",
    "tn, fp, fn, tp = cm_lgbm.ravel()\n",
    "cout_lgbm = (fn * 10) + (fp * 1)\n",
    "\n",
    "print(f\"\\n RÉSULTATS :\")\n",
    "print(f\" Temps : {time_lgbm:.2f}s\")\n",
    "print(f\" AUC : {auc_lgbm:.4f}\")\n",
    "print(f\" Recall : {recall_lgbm:.4f}\")\n",
    "print(f\" Precision : {precision_lgbm:.4f}\")\n",
    "print(f\" F1-Score : {f1_lgbm:.4f}\")\n",
    "print(f\" Coût métier (10×FN + 1×FP) : {cout_lgbm:,}€\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des 5 Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPARAISON DES 5 MODÈLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Créer le DataFrame de résultats\n",
    "results = pd.DataFrame({\n",
    "'Modèle': ['DummyClassifier', 'LogisticRegression', 'RandomForest', 'XGBoost', 'LightGBM'],\n",
    "'AUC': [auc_dummy, auc_logreg, auc_rf, auc_xgb, auc_lgbm],\n",
    "'Recall': [recall_dummy, recall_logreg, recall_rf, recall_xgb, recall_lgbm],\n",
    "'Precision': [precision_dummy, precision_logreg, precision_rf, precision_xgb, precision_lgbm],\n",
    "'F1-Score': [f1_dummy, f1_logreg, f1_rf, f1_xgb, f1_lgbm],\n",
    "'Coût métier': [cout_dummy, cout_logreg, cout_rf, cout_xgb, cout_lgbm],\n",
    "'Temps (s)': [time_dummy, time_logreg, time_rf, time_xgb, time_lgbm]\n",
    "})\n",
    "\n",
    "# Trier par AUC décroissant\n",
    "results = results.sort_values('AUC', ascending=False)\n",
    "\n",
    "print(\"\\n Tableau récapitulatif (trié par AUC) :\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Meilleur modèle\n",
    "best = results.iloc[0]\n",
    "print(f\"\\n MEILLEUR MODÈLE : {best['Modèle']}\")\n",
    "print(f\" AUC : {best['AUC']:.4f}\")\n",
    "print(f\" Recall : {best['Recall']:.4f}\")\n",
    "print(f\" Coût métier : {best['Coût métier']:,.0f}€\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPARAISON TERMINÉE !\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 : Courbes ROC\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Courbes ROC\n",
    "fpr_dummy, tpr_dummy, _ = roc_curve(y_valid, y_proba_dummy)\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_valid, y_proba_logreg)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_valid, y_proba_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_valid, y_proba_xgb)\n",
    "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_valid, y_proba_lgbm)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', label='Modèle aléatoire (AUC = 0.50)', linewidth=2)\n",
    "ax1.plot(fpr_dummy, tpr_dummy, label=f'DummyClassifier (AUC = {auc_dummy:.3f})', linewidth=2)\n",
    "ax1.plot(fpr_logreg, tpr_logreg, label=f'LogisticRegression (AUC = {auc_logreg:.3f})', linewidth=2)\n",
    "ax1.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC = {auc_rf:.3f})', linewidth=2)\n",
    "ax1.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})', linewidth=2)\n",
    "ax1.plot(fpr_lgbm, tpr_lgbm, label=f'LightGBM (AUC = {auc_lgbm:.3f})', linewidth=2)\n",
    "ax1.set_xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
    "ax1.set_ylabel('Taux de Vrais Positifs (TPR / Recall)', fontsize=12)\n",
    "ax1.set_title('Courbes ROC - Comparaison des 5 modèles sur Validation Set', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Barres de comparaison AUC et Coût\n",
    "x = np.arange(len(results))\n",
    "ax2_twin = ax2.twinx()\n",
    "\n",
    "bars1 = ax2.barh(x, results['AUC'], height=0.4, alpha=0.8, label='AUC', color='steelblue')\n",
    "bars2 = ax2_twin.barh(x + 0.4, results['Coût métier'], height=0.4, alpha=0.8, label='Coût métier', color='coral')\n",
    "\n",
    "ax2.set_yticks(x + 0.2)\n",
    "ax2.set_yticklabels(results['Modèle'])\n",
    "ax2.set_xlabel('AUC', fontsize=12, color='steelblue')\n",
    "ax2_twin.set_xlabel('Coût métier (€)', fontsize=12, color='coral')\n",
    "ax2.set_title('AUC et Coût métier par modèle', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(0.5, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Baseline (0.5)')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2_twin.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nb03_fig01_comparaison_modeles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Figure sauvegardée : nb03_fig01_comparaison_modeles.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2 : Matrices de confusion\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "cms = [cm_dummy, cm_logreg, cm_rf, cm_xgb, cm_lgbm]\n",
    "titles = ['DummyClassifier', 'LogisticRegression', 'RandomForest', 'XGBoost', 'LightGBM']\n",
    "\n",
    "for ax, cm, title in zip(axes, cms, titles):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Prédiction', fontsize=10)\n",
    "    ax.set_ylabel('Réalité', fontsize=10)\n",
    "    ax.set_xticklabels(['Remboursement (0)', 'Défaut (1)'])\n",
    "    ax.set_yticklabels(['Remboursement (0)', 'Défaut (1)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nb03_fig02_matrices_confusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure sauvegardée : nb03_fig02_matrices_confusion.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du Meilleur Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le meilleur modèle (LightGBM)\n",
    "joblib.dump(lgbm, './artifacts/meilleur_modele.joblib')\n",
    "print(\" Meilleur modèle sauvegardé : ./artifacts/meilleur_modele.joblib\")\n",
    "\n",
    "# Sauvegarder les résultats\n",
    "results.to_csv('./artifacts/comparaison_modeles.csv', index=False)\n",
    "print(\" Résultats sauvegardés : ./artifacts/comparaison_modeles.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" NOTEBOOK 03 TERMINÉ !\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
