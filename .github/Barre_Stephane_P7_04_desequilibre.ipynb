{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04 : SMOTE vs Class Weight - CORRIGÉ\n",
    "\n",
    "**Objectif** : Comparer deux approches pour gérer le déséquilibre des classes\n",
    "\n",
    "## Contenu\n",
    "1. Chargement sécurisé des données (avec fallback)\n",
    "2. Comparaison SMOTE vs class_weight\n",
    "3. Analyse des résultats\n",
    "4. Décision finale\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, recall_score, \n",
    "    precision_score, f1_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement Sécurisé des Données\n",
    "\n",
    "On essaie de charger les artifacts. Si ça échoue, on recharge depuis les données brutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    DOSSIER_ARTIFACTS = current_dir.parent / 'artifacts'\n",
    "    DOSSIER_DATA = current_dir.parent / 'data'\n",
    "else:\n",
    "    DOSSIER_ARTIFACTS = current_dir / 'artifacts'\n",
    "    DOSSIER_DATA = current_dir / 'data'\n",
    "\n",
    "print(f\"Dossier artifacts: {DOSSIER_ARTIFACTS}\")\n",
    "print(f\"Dossier data: {DOSSIER_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de chargement sécurisé\n",
    "def charger_donnees():\n",
    "    \"\"\"\n",
    "    Tente de charger les données depuis artifacts.\n",
    "    Si échec, recharge depuis les données brutes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tentative 1 : Charger depuis artifacts\n",
    "    try:\n",
    "        print(\"Tentative de chargement depuis artifacts...\")\n",
    "        \n",
    "        data_split_path = DOSSIER_ARTIFACTS / 'data_split.joblib'\n",
    "        if not data_split_path.exists():\n",
    "            raise FileNotFoundError(\"data_split.joblib non trouve\")\n",
    "        \n",
    "        data = joblib.load(data_split_path)\n",
    "        \n",
    "        # Vérifier le format\n",
    "        if isinstance(data, dict):\n",
    "            X_train = data['X_train_processed']\n",
    "            X_valid = data['X_valid_processed']\n",
    "            y_train = data['y_train']\n",
    "            y_valid = data['y_valid']\n",
    "        else:\n",
    "            X_train, X_valid, y_train, y_valid = data\n",
    "        \n",
    "        print(f\"OK - Chargement depuis artifacts reussi\")\n",
    "        print(f\"  X_train shape: {X_train.shape}\")\n",
    "        print(f\"  y_train shape: {y_train.shape}\")\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Echec du chargement depuis artifacts: {e}\")\n",
    "        print(\"\\nTentative de rechargement depuis donnees brutes...\")\n",
    "        \n",
    "        # Tentative 2 : Recharger depuis données brutes\n",
    "        # Chercher le fichier agrégé ou brut\n",
    "        fichier_aggr = DOSSIER_DATA / 'application_train_AGGREGATED.csv'\n",
    "        fichier_brut = DOSSIER_DATA / 'application_train.csv'\n",
    "        \n",
    "        if fichier_aggr.exists():\n",
    "            print(f\"Chargement de {fichier_aggr.name}...\")\n",
    "            df = pd.read_csv(fichier_aggr)\n",
    "        elif fichier_brut.exists():\n",
    "            print(f\"Chargement de {fichier_brut.name}...\")\n",
    "            df = pd.read_csv(fichier_brut)\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                \"Aucun fichier de donnees trouve. \"\n",
    "                \"Executez le Notebook 01 ou placez application_train.csv dans data/\"\n",
    "            )\n",
    "        \n",
    "        print(f\"OK - Donnees chargees: {df.shape}\")\n",
    "        \n",
    "        # Préparation rapide\n",
    "        X = df.drop(columns=['SK_ID_CURR', 'TARGET'], errors='ignore')\n",
    "        y = df['TARGET']\n",
    "        \n",
    "        # Garder seulement les colonnes numériques pour simplifier\n",
    "        X = X.select_dtypes(include=['int64', 'float64'])\n",
    "        \n",
    "        # Remplir les NaN avec la médiane\n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        print(f\"Preprocessing simple applique\")\n",
    "        print(f\"  Features numeriques: {X.shape[1]}\")\n",
    "        \n",
    "        # Split\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nSplit effectue:\")\n",
    "        print(f\"  X_train: {X_train.shape}\")\n",
    "        print(f\"  X_valid: {X_valid.shape}\")\n",
    "        \n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "# Charger les données\n",
    "X_train, X_valid, y_train, y_valid = charger_donnees()\n",
    "\n",
    "print(f\"\\nDistribution y_train:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline (Sans Correction du Déséquilibre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE : Sans correction du desequilibre\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Libérer la mémoire\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 1 : Optimiser les types de données\n",
    "print(\"Optimisation des types de données...\")\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "        X_valid[col] = pd.to_numeric(X_valid[col], errors='coerce')\n",
    "    \n",
    "    if X_train[col].dtype in ['float64', 'int64']:\n",
    "        X_train[col] = X_train[col].astype('float32')\n",
    "        X_valid[col] = X_valid[col].astype('float32')\n",
    "\n",
    "print(\"Optimisation terminée!\")\n",
    "\n",
    "# ÉTAPE 2 : Vérifier et gérer les valeurs manquantes\n",
    "print(f\"\\nNombre de NaN dans X_train: {X_train.isna().sum().sum()}\")\n",
    "print(f\"Nombre de NaN dans X_valid: {X_valid.isna().sum().sum()}\")\n",
    "\n",
    "# Imputation des valeurs manquantes avec la médiane\n",
    "print(\"\\nImputation des valeurs manquantes...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_valid_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_valid),\n",
    "    columns=X_valid.columns,\n",
    "    index=X_valid.index\n",
    ")\n",
    "\n",
    "print(\"Imputation terminée!\")\n",
    "print(f\"NaN restants dans X_train: {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"NaN restants dans X_valid: {X_valid_imputed.isna().sum().sum()}\")\n",
    "\n",
    "# Libérer la mémoire\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 3 : Entraîner le modèle\n",
    "start = time.time()\n",
    "model_baseline = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=8,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_samples=0.8\n",
    ")\n",
    "\n",
    "print(\"\\nEntraînement du modèle...\")\n",
    "model_baseline.fit(X_train_imputed, y_train)\n",
    "y_pred_baseline = model_baseline.predict(X_valid_imputed)\n",
    "y_proba_baseline = model_baseline.predict_proba(X_valid_imputed)[:, 1]\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Métriques\n",
    "metrics_baseline = {\n",
    "    'AUC': roc_auc_score(y_valid, y_proba_baseline),\n",
    "    'Accuracy': accuracy_score(y_valid, y_pred_baseline),\n",
    "    'Recall': recall_score(y_valid, y_pred_baseline),\n",
    "    'Precision': precision_score(y_valid, y_pred_baseline),\n",
    "    'F1': f1_score(y_valid, y_pred_baseline),\n",
    "    'Temps (s)': elapsed\n",
    "}\n",
    "\n",
    "print(f\"\\nResultats:\")\n",
    "for metric, value in metrics_baseline.items():\n",
    "    if metric == 'Temps (s)':\n",
    "        print(f\"  {metric}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_baseline = confusion_matrix(y_valid, y_pred_baseline)\n",
    "print(f\"\\nMatrice de confusion:\")\n",
    "print(cm_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approche 1 : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"APPROCHE 1 : SMOTE (Synthetic Minority Over-sampling)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Libérer la mémoire\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 1 : Optimiser les types de données\n",
    "print(\"Optimisation des types de données...\")\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "        X_valid[col] = pd.to_numeric(X_valid[col], errors='coerce')\n",
    "    \n",
    "    if X_train[col].dtype in ['float64', 'int64']:\n",
    "        X_train[col] = X_train[col].astype('float32')\n",
    "        X_valid[col] = X_valid[col].astype('float32')\n",
    "\n",
    "print(\"Optimisation terminée!\")\n",
    "\n",
    "# ÉTAPE 2 : Imputation des valeurs manquantes\n",
    "print(\"\\nImputation des valeurs manquantes...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_valid_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_valid),\n",
    "    columns=X_valid.columns,\n",
    "    index=X_valid.index\n",
    ")\n",
    "\n",
    "print(f\"NaN restants dans X_train: {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"NaN restants dans X_valid: {X_valid_imputed.isna().sum().sum()}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 3 : Application de SMOTE\n",
    "start = time.time()\n",
    "print(\"\\nApplication de SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_imputed, y_train)\n",
    "\n",
    "print(f\"\\nAvant SMOTE:\")\n",
    "print(f\"  Shape: {X_train_imputed.shape}\")\n",
    "print(f\"  Distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"\\nApres SMOTE:\")\n",
    "print(f\"  Shape: {X_train_smote.shape}\")\n",
    "print(f\"  Distribution: {pd.Series(y_train_smote).value_counts().to_dict()}\")\n",
    "\n",
    "# ÉTAPE 4 : Entraîner le modèle\n",
    "print(f\"\\nEntrainement du modele...\")\n",
    "model_smote = RandomForestClassifier(\n",
    "    n_estimators=50,      # Réduit pour économiser la mémoire\n",
    "    max_depth=8,          # Réduit pour économiser la mémoire\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_samples=0.8\n",
    ")\n",
    "\n",
    "model_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = model_smote.predict(X_valid_imputed)\n",
    "y_proba_smote = model_smote.predict_proba(X_valid_imputed)[:, 1]\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Métriques\n",
    "metrics_smote = {\n",
    "    'AUC': roc_auc_score(y_valid, y_proba_smote),\n",
    "    'Accuracy': accuracy_score(y_valid, y_pred_smote),\n",
    "    'Recall': recall_score(y_valid, y_pred_smote),\n",
    "    'Precision': precision_score(y_valid, y_pred_smote),\n",
    "    'F1': f1_score(y_valid, y_pred_smote),\n",
    "    'Temps (s)': elapsed\n",
    "}\n",
    "\n",
    "print(f\"\\nResultats:\")\n",
    "for metric, value in metrics_smote.items():\n",
    "    if metric == 'Temps (s)':\n",
    "        print(f\"  {metric}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_smote = confusion_matrix(y_valid, y_pred_smote)\n",
    "print(f\"\\nMatrice de confusion:\")\n",
    "print(cm_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Approche 2 : Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"APPROCHE 2 : Class Weight (Balanced)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Libérer la mémoire\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 1 : Vérifier si l'imputation a déjà été faite\n",
    "# Si X_train_imputed n'existe pas encore, faire l'imputation\n",
    "try:\n",
    "    _ = X_train_imputed\n",
    "    print(\"Utilisation des données déjà imputées\")\n",
    "except NameError:\n",
    "    print(\"Optimisation des types de données...\")\n",
    "    for col in X_train.columns:\n",
    "        if X_train[col].dtype == 'object':\n",
    "            X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "            X_valid[col] = pd.to_numeric(X_valid[col], errors='coerce')\n",
    "        \n",
    "        if X_train[col].dtype in ['float64', 'int64']:\n",
    "            X_train[col] = X_train[col].astype('float32')\n",
    "            X_valid[col] = X_valid[col].astype('float32')\n",
    "    \n",
    "    print(\"Imputation des valeurs manquantes...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    X_valid_imputed = pd.DataFrame(\n",
    "        imputer.transform(X_valid),\n",
    "        columns=X_valid.columns,\n",
    "        index=X_valid.index\n",
    "    )\n",
    "    print(f\"NaN restants: {X_train_imputed.isna().sum().sum()}\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# ÉTAPE 2 : Entraîner le modèle avec class_weight\n",
    "start = time.time()\n",
    "model_balanced = RandomForestClassifier(\n",
    "    n_estimators=50,           # Réduit pour économiser la mémoire\n",
    "    max_depth=8,               # Réduit pour économiser la mémoire\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced',   # Ajustement automatique des poids\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_samples=0.8\n",
    ")\n",
    "\n",
    "print(\"Entrainement du modele avec class_weight='balanced'...\")\n",
    "model_balanced.fit(X_train_imputed, y_train)\n",
    "y_pred_balanced = model_balanced.predict(X_valid_imputed)\n",
    "y_proba_balanced = model_balanced.predict_proba(X_valid_imputed)[:, 1]\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Métriques\n",
    "metrics_balanced = {\n",
    "    'AUC': roc_auc_score(y_valid, y_proba_balanced),\n",
    "    'Accuracy': accuracy_score(y_valid, y_pred_balanced),\n",
    "    'Recall': recall_score(y_valid, y_pred_balanced),\n",
    "    'Precision': precision_score(y_valid, y_pred_balanced),\n",
    "    'F1': f1_score(y_valid, y_pred_balanced),\n",
    "    'Temps (s)': elapsed\n",
    "}\n",
    "\n",
    "print(f\"\\nResultats:\")\n",
    "for metric, value in metrics_balanced.items():\n",
    "    if metric == 'Temps (s)':\n",
    "        print(f\"  {metric}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_balanced = confusion_matrix(y_valid, y_pred_balanced)\n",
    "print(f\"\\nMatrice de confusion:\")\n",
    "print(cm_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparaison Visuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataFrame de comparaison\n",
    "results_df = pd.DataFrame({\n",
    "    'Baseline': metrics_baseline,\n",
    "    'SMOTE': metrics_smote,\n",
    "    'Class Weight': metrics_balanced\n",
    "}).T\n",
    "\n",
    "print(\"\\nTableau comparatif:\")\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "metrics_to_plot = ['AUC', 'Recall', 'Precision', 'F1', 'Accuracy', 'Temps (s)']\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    data = results_df[metric]\n",
    "    colors = ['gray', 'orange', 'green']\n",
    "    \n",
    "    bars = ax.bar(data.index, data.values, color=colors, alpha=0.7)\n",
    "    ax.set_title(f'{metric}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score' if metric != 'Temps (s)' else 'Secondes')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}' if metric != 'Temps (s)' else f'{height:.1f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/04_smote_vs_classweight.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGraphique sauvegarde: ../figures/04_smote_vs_classweight.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Matrices de Confusion Comparées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "cms = [\n",
    "    (cm_baseline, 'Baseline'),\n",
    "    (cm_smote, 'SMOTE'),\n",
    "    (cm_balanced, 'Class Weight')\n",
    "]\n",
    "\n",
    "for idx, (cm, title) in enumerate(cms):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                cbar=False, square=True)\n",
    "    axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Vraie Classe')\n",
    "    axes[idx].set_xlabel('Classe Predite')\n",
    "    axes[idx].set_xticklabels(['Rembourse', 'Defaut'])\n",
    "    axes[idx].set_yticklabels(['Rembourse', 'Defaut'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/04_confusion_matrices_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGraphique sauvegarde: ../figures/04_confusion_matrices_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse et Décision Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ANALYSE ET DECISION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. RECALL (Detection des defauts - PRIORITE):\")\n",
    "print(f\"   Baseline:     {metrics_baseline['Recall']:.4f}\")\n",
    "print(f\"   SMOTE:        {metrics_smote['Recall']:.4f} ({(metrics_smote['Recall']-metrics_baseline['Recall'])*100:+.1f}%)\")\n",
    "print(f\"   Class Weight: {metrics_balanced['Recall']:.4f} ({(metrics_balanced['Recall']-metrics_baseline['Recall'])*100:+.1f}%)\")\n",
    "\n",
    "print(\"\\n2. AUC (Capacite discriminante globale):\")\n",
    "print(f\"   Baseline:     {metrics_baseline['AUC']:.4f}\")\n",
    "print(f\"   SMOTE:        {metrics_smote['AUC']:.4f} ({(metrics_smote['AUC']-metrics_baseline['AUC'])*100:+.1f}%)\")\n",
    "print(f\"   Class Weight: {metrics_balanced['AUC']:.4f} ({(metrics_balanced['AUC']-metrics_baseline['AUC'])*100:+.1f}%)\")\n",
    "\n",
    "print(\"\\n3. F1-SCORE (Equilibre global):\")\n",
    "print(f\"   Baseline:     {metrics_baseline['F1']:.4f}\")\n",
    "print(f\"   SMOTE:        {metrics_smote['F1']:.4f} ({(metrics_smote['F1']-metrics_baseline['F1'])*100:+.1f}%)\")\n",
    "print(f\"   Class Weight: {metrics_balanced['F1']:.4f} ({(metrics_balanced['F1']-metrics_baseline['F1'])*100:+.1f}%)\")\n",
    "\n",
    "print(\"\\n4. TEMPS D'ENTRAINEMENT:\")\n",
    "print(f\"   Baseline:     {metrics_baseline['Temps (s)']:.1f}s\")\n",
    "print(f\"   SMOTE:        {metrics_smote['Temps (s)']:.1f}s ({metrics_smote['Temps (s)']/metrics_baseline['Temps (s)']:.1f}x)\")\n",
    "print(f\"   Class Weight: {metrics_balanced['Temps (s)']:.1f}s ({metrics_balanced['Temps (s)']/metrics_baseline['Temps (s)']:.1f}x)\")\n",
    "\n",
    "# Déterminer le gagnant\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DECISION FINALE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if metrics_balanced['Recall'] >= metrics_smote['Recall'] and \\\n",
    "   metrics_balanced['AUC'] >= metrics_smote['AUC'] and \\\n",
    "   metrics_balanced['Temps (s)'] < metrics_smote['Temps (s)']:\n",
    "    print(\"\\nAPPROCHE RETENUE : CLASS_WEIGHT='BALANCED'\")\n",
    "    print(\"\\nJustifications:\")\n",
    "    print(\"  1. Recall superieur ou egal a SMOTE\")\n",
    "    print(\"  2. AUC superieur ou egal\")\n",
    "    print(\"  3. Temps d'entrainement plus rapide (important pour re-training)\")\n",
    "    print(\"  4. Pas de generation de donnees synthetiques (plus fiable)\")\n",
    "    print(\"  5. Simplicite d'implementation (un seul parametre)\")\n",
    "else:\n",
    "    print(\"\\nAPPROCHE RETENUE : SMOTE\")\n",
    "    print(\"\\nJustifications:\")\n",
    "    print(\"  1. Meilleurs performances globales\")\n",
    "    print(\"  2. Recall ameliore significativement\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pour les notebooks suivants, utiliser RandomForestClassifier\")\n",
    "print(\"avec class_weight='balanced' (ou SMOTE selon decision)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde de la Décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les résultats\n",
    "resultats = {\n",
    "    'approche_retenue': 'class_weight' if metrics_balanced['Recall'] >= metrics_smote['Recall'] else 'smote',\n",
    "    'metrics_baseline': metrics_baseline,\n",
    "    'metrics_smote': metrics_smote,\n",
    "    'metrics_balanced': metrics_balanced,\n",
    "    'comparaison_df': results_df\n",
    "}\n",
    "\n",
    "# Créer le dossier artifacts s'il n'existe pas\n",
    "DOSSIER_ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "# Sauvegarder\n",
    "chemin_resultats = DOSSIER_ARTIFACTS / 'notebook04_resultats.joblib'\n",
    "joblib.dump(resultats, chemin_resultats)\n",
    "\n",
    "print(f\"\\nResultats sauvegardes: {chemin_resultats}\")\n",
    "print(f\"\\nApproche retenue: {resultats['approche_retenue'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
