{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 7 PREMIUM - Étape 4 : Score Métier et Optimisation Seuil\n",
    "\n",
    "**Objectif** : Optimiser le seuil selon le coût métier (10×FN + 1×FP)\n",
    "\n",
    "## Contenu\n",
    "1. Fonction de coût métier\n",
    "2. Balayage des seuils (201 valeurs)\n",
    "3. Identification seuil optimal\n",
    "4. Comparaison vs seuil par défaut (0.5)\n",
    "5. Sauvegarde pipeline final\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(' Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données et modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger données et meilleur modèle\n",
    "DOSSIER_ARTIFACTS = Path('../artifacts').resolve()\n",
    "X_train, X_valid, y_train, y_valid = joblib.load(DOSSIER_ARTIFACTS / 'data_split.joblib')\n",
    "pipeline = joblib.load(DOSSIER_ARTIFACTS / 'meilleur_modele.joblib')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRÉPARATION DES DONNÉES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDimensions initiales:\")\n",
    "print(f\" X_train: {X_train.shape}\")\n",
    "print(f\" X_valid: {X_valid.shape}\")\n",
    "print(f\" y_train: {len(y_train)}\")\n",
    "print(f\" y_valid: {len(y_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignement des features avec le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les features attendues par le modèle\n",
    "try:\n",
    " expected_features = pipeline.feature_name_\n",
    " print(\" Features récupérées via feature_name_\")\n",
    "except:\n",
    " try:\n",
    " expected_features = pipeline.booster_.feature_name()\n",
    " print(\" Features récupérées via booster_.feature_name()\")\n",
    " except:\n",
    " try:\n",
    " expected_features = pipeline._Booster.feature_name()\n",
    " print(\" Features récupérées via _Booster.feature_name()\")\n",
    " except:\n",
    " print(\" Impossible de récupérer les features du modèle\")\n",
    " raise ValueError(\"Cannot retrieve model features\")\n",
    "\n",
    "print(f\"\\nFeatures attendues par le modèle: {len(expected_features)}\")\n",
    "print(f\"Features dans X_valid: {len(X_valid.columns)}\")\n",
    "\n",
    "# Identifier les différences\n",
    "current_cols = set(X_valid.columns)\n",
    "expected_cols = set(expected_features)\n",
    "\n",
    "missing_cols = list(expected_cols - current_cols)\n",
    "extra_cols = list(current_cols - expected_cols)\n",
    "\n",
    "print(f\"\\nColonnes manquantes: {len(missing_cols)}\")\n",
    "if len(missing_cols) > 0 and len(missing_cols) <= 20:\n",
    " print(f\" {missing_cols}\")\n",
    "elif len(missing_cols) > 20:\n",
    " print(f\" {missing_cols[:5]}... (+{len(missing_cols)-5} autres)\")\n",
    "\n",
    "print(f\"\\nColonnes en trop: {len(extra_cols)}\")\n",
    "if len(extra_cols) > 0 and len(extra_cols) <= 20:\n",
    " print(f\" {extra_cols}\")\n",
    "elif len(extra_cols) > 20:\n",
    " print(f\" {extra_cols[:5]}... (+{len(extra_cols)-5} autres)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMISATION: Ajouter toutes les colonnes manquantes en une seule fois\n",
    "if len(missing_cols) > 0:\n",
    " print(f\"\\nAjout de {len(missing_cols)} colonnes manquantes...\")\n",
    " \n",
    " # Créer un DataFrame avec toutes les colonnes manquantes\n",
    " missing_df_valid = pd.DataFrame(0, index=X_valid.index, columns=missing_cols)\n",
    " missing_df_train = pd.DataFrame(0, index=X_train.index, columns=missing_cols)\n",
    " \n",
    " # Concaténer en une seule fois (beaucoup plus efficace)\n",
    " X_valid = pd.concat([X_valid, missing_df_valid], axis=1)\n",
    " X_train = pd.concat([X_train, missing_df_train], axis=1)\n",
    " \n",
    " print(\" Colonnes manquantes ajoutées\")\n",
    "\n",
    "# Supprimer les colonnes en trop\n",
    "if len(extra_cols) > 0:\n",
    " print(f\"\\nSuppression de {len(extra_cols)} colonnes en trop...\")\n",
    " X_valid = X_valid.drop(columns=extra_cols)\n",
    " X_train = X_train.drop(columns=extra_cols)\n",
    " print(\" Colonnes en trop supprimées\")\n",
    "\n",
    "# Réordonner les colonnes dans le bon ordre\n",
    "print(\"\\nRéordonnancement des colonnes...\")\n",
    "X_valid = X_valid[expected_features]\n",
    "X_train = X_train[expected_features]\n",
    "print(\" Colonnes réordonnées\")\n",
    "\n",
    "print(f\"\\nDimensions après alignement:\")\n",
    "print(f\" X_train: {X_train.shape}\")\n",
    "print(f\" X_valid: {X_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion des types de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CONVERSION DES TYPES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identifier les colonnes object\n",
    "object_cols = X_valid.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nColonnes 'object' à convertir: {len(object_cols)}\")\n",
    "\n",
    "if len(object_cols) > 0:\n",
    " print(\"Exemples de valeurs:\")\n",
    " for col in object_cols[:3]:\n",
    " print(f\" {col}: {X_valid[col].unique()[:3]}\")\n",
    "\n",
    "# Convertir les colonnes object en numérique\n",
    "if len(object_cols) > 0:\n",
    " print(f\"\\nConversion de {len(object_cols)} colonnes...\")\n",
    " for col in object_cols:\n",
    " X_valid[col] = pd.to_numeric(X_valid[col], errors='coerce')\n",
    " X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    " print(\" Conversion terminée\")\n",
    "\n",
    "# Gérer les valeurs manquantes\n",
    "nan_count_valid = X_valid.isna().sum().sum()\n",
    "nan_count_train = X_train.isna().sum().sum()\n",
    "\n",
    "print(f\"\\nValeurs NaN à traiter:\")\n",
    "print(f\" X_valid: {nan_count_valid:,}\")\n",
    "print(f\" X_train: {nan_count_train:,}\")\n",
    "\n",
    "if nan_count_valid > 0 or nan_count_train > 0:\n",
    " X_valid = X_valid.fillna(0)\n",
    " X_train = X_train.fillna(0)\n",
    " print(\" Valeurs NaN remplacées par 0\")\n",
    "\n",
    "# Vérification finale\n",
    "print(f\"\\nTypes de données finaux:\")\n",
    "print(X_valid.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\nVérification des NaN restants:\")\n",
    "print(f\" X_valid: {X_valid.isna().sum().sum()}\")\n",
    "print(f\" X_train: {X_train.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des probabilités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GÉNÉRATION DES PRÉDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Générer les probabilités\n",
    "print(\"\\nGénération des probabilités...\")\n",
    "proba_valid = pipeline.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "print(f\"\\n Probabilités générées: {len(proba_valid):,}\")\n",
    "print(f\"\\nStatistiques des probabilités:\")\n",
    "print(f\" Min: {proba_valid.min():.4f}\")\n",
    "print(f\" Max: {proba_valid.max():.4f}\")\n",
    "print(f\" Moyenne: {proba_valid.mean():.4f}\")\n",
    "print(f\" Médiane: {np.median(proba_valid):.4f}\")\n",
    "print(f\" Q25: {np.percentile(proba_valid, 25):.4f}\")\n",
    "print(f\" Q75: {np.percentile(proba_valid, 75):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de coût métier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cout_metier(y_true, y_pred, cout_fn=10, cout_fp=1):\n",
    " \"\"\"\n",
    " Calcule le coût métier : cout_fn × FN + cout_fp × FP\n",
    " \n",
    " Paramètres:\n",
    " -----------\n",
    " y_true : array-like\n",
    " Vraies étiquettes\n",
    " y_pred : array-like\n",
    " Prédictions\n",
    " cout_fn : float, default=10\n",
    " Coût d'un faux négatif (ne pas détecter un défaut)\n",
    " cout_fp : float, default=1\n",
    " Coût d'un faux positif (refuser à tort)\n",
    " \n",
    " Retourne:\n",
    " ---------\n",
    " cout_total : float\n",
    " Coût total\n",
    " \"\"\"\n",
    " tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    " return cout_fn * fn + cout_fp * fp\n",
    "\n",
    "print(\" Fonction de coût métier définie\")\n",
    "print(\"\\nFormule : Coût = 10 × FN + 1 × FP\")\n",
    "print(\" - FN (Faux Négatif) : Ne pas détecter un défaut → Perte de 10 unités\")\n",
    "print(\" - FP (Faux Positif) : Refuser à tort → Perte de 1 unité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balayage des seuils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"OPTIMISATION DU SEUIL DE DÉCISION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Définir la plage de seuils à tester\n",
    "seuils = np.linspace(0, 1, 201)\n",
    "couts = []\n",
    "\n",
    "print(f\"\\nTest de {len(seuils)} seuils...\")\n",
    "print(f\" Plage : {seuils.min():.3f} à {seuils.max():.3f}\")\n",
    "print(f\" Pas : {seuils[1] - seuils[0]:.4f}\")\n",
    "\n",
    "# Calculer le coût pour chaque seuil\n",
    "for seuil in seuils:\n",
    " y_pred = (proba_valid >= seuil).astype(int)\n",
    " cout = cout_metier(y_valid, y_pred)\n",
    " couts.append(cout)\n",
    "\n",
    "# Trouver le seuil optimal\n",
    "idx_optimal = np.argmin(couts)\n",
    "seuil_optimal = seuils[idx_optimal]\n",
    "cout_optimal = couts[idx_optimal]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RÉSULTATS DE L'OPTIMISATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n SEUIL OPTIMAL : {seuil_optimal:.4f}\")\n",
    "print(f\" Coût optimal : {cout_optimal:,.0f} unités\")\n",
    "print(f\" Position : {idx_optimal}/{len(seuils)} seuils testés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison avec le seuil par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les métriques pour le seuil par défaut (0.5)\n",
    "y_pred_default = (proba_valid >= 0.5).astype(int)\n",
    "cout_default = cout_metier(y_valid, y_pred_default)\n",
    "\n",
    "# Calculer les métriques pour le seuil optimal\n",
    "y_pred_optimal = (proba_valid >= seuil_optimal).astype(int)\n",
    "\n",
    "# Matrices de confusion\n",
    "cm_default = confusion_matrix(y_valid, y_pred_default)\n",
    "cm_optimal = confusion_matrix(y_valid, y_pred_optimal)\n",
    "\n",
    "# Calculer le gain\n",
    "gain = cout_default - cout_optimal\n",
    "gain_pct = (gain / cout_default) * 100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPARAISON SEUIL PAR DÉFAUT vs SEUIL OPTIMAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n SEUIL PAR DÉFAUT (0.500):\")\n",
    "print(f\" Coût total : {cout_default:,.0f} unités\")\n",
    "print(f\" Matrice de confusion:\")\n",
    "print(f\" TN={cm_default[0,0]:,} FP={cm_default[0,1]:,}\")\n",
    "print(f\" FN={cm_default[1,0]:,} TP={cm_default[1,1]:,}\")\n",
    "\n",
    "print(f\"\\n SEUIL OPTIMAL ({seuil_optimal:.4f}):\")\n",
    "print(f\" Coût total : {cout_optimal:,.0f} unités\")\n",
    "print(f\" Matrice de confusion:\")\n",
    "print(f\" TN={cm_optimal[0,0]:,} FP={cm_optimal[0,1]:,}\")\n",
    "print(f\" FN={cm_optimal[1,0]:,} TP={cm_optimal[1,1]:,}\")\n",
    "\n",
    "print(f\"\\n GAIN:\")\n",
    "print(f\" Réduction de coût : {gain:,.0f} unités\")\n",
    "print(f\" Amélioration : {gain_pct:.2f}%\")\n",
    "\n",
    "if gain > 0:\n",
    " print(f\"\\n Le seuil optimal améliore significativement les performances!\")\n",
    "else:\n",
    " print(f\"\\n Le seuil par défaut est déjà performant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le graphique\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Courbe du coût en fonction du seuil\n",
    "plt.plot(seuils, couts, linewidth=2, label='Coût métier', color='steelblue')\n",
    "\n",
    "# Marquer le seuil optimal\n",
    "plt.axvline(seuil_optimal, color='green', linestyle='--', linewidth=2, \n",
    " label=f'Seuil optimal ({seuil_optimal:.4f})')\n",
    "plt.scatter([seuil_optimal], [cout_optimal], color='green', s=200, zorder=5,\n",
    " marker='*', edgecolors='darkgreen', linewidths=2)\n",
    "\n",
    "# Marquer le seuil par défaut\n",
    "plt.axvline(0.5, color='red', linestyle='--', linewidth=2, alpha=0.7,\n",
    " label=f'Seuil par défaut (0.500)')\n",
    "plt.scatter([0.5], [cout_default], color='red', s=200, zorder=5,\n",
    " marker='X', edgecolors='darkred', linewidths=2)\n",
    "\n",
    "plt.xlabel('Seuil de décision', fontsize=12)\n",
    "plt.ylabel('Coût métier (10×FN + 1×FP)', fontsize=12)\n",
    "plt.title('Optimisation du seuil de décision selon le coût métier', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarder le graphique\n",
    "plt.savefig(DOSSIER_ARTIFACTS / 'optimisation_seuil.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n Graphique sauvegardé : optimisation_seuil.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du pipeline final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SAUVEGARDE DU PIPELINE FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Créer un dictionnaire avec tous les paramètres de décision\n",
    "parametres_decision = {\n",
    " 'seuil_optimal': seuil_optimal,\n",
    " 'cout_optimal': cout_optimal,\n",
    " 'cout_default': cout_default,\n",
    " 'gain': gain,\n",
    " 'gain_pct': gain_pct,\n",
    " 'cout_fn': 10,\n",
    " 'cout_fp': 1,\n",
    " 'n_seuils_testes': len(seuils)\n",
    "}\n",
    "\n",
    "# Sauvegarder le pipeline\n",
    "joblib.dump(pipeline, DOSSIER_ARTIFACTS / 'pipeline_final.joblib')\n",
    "\n",
    "# Sauvegarder les paramètres de décision\n",
    "joblib.dump(parametres_decision, DOSSIER_ARTIFACTS / 'parametres_decision.joblib')\n",
    "\n",
    "# Sauvegarder les noms de colonnes\n",
    "joblib.dump(list(X_valid.columns), DOSSIER_ARTIFACTS / 'feature_names.joblib')\n",
    "\n",
    "print(\"\\n SAUVEGARDE TERMINÉE\")\n",
    "print(f\" Dossier: {DOSSIER_ARTIFACTS}\")\n",
    "print(f\" Pipeline final: pipeline_final.joblib\")\n",
    "print(f\" Paramètres métier: parametres_decision.joblib\")\n",
    "print(f\" Feature names: feature_names.joblib\")\n",
    "\n",
    "print(f\"\\n PARAMÈTRES SAUVEGARDÉS:\")\n",
    "for k, v in parametres_decision.items():\n",
    " if isinstance(v, float):\n",
    " print(f\" {k}: {v:.4f}\")\n",
    " else:\n",
    " print(f\" {k}: {v}\")\n",
    "\n",
    "print(f\"\\n POUR CHARGER EN PRODUCTION:\")\n",
    "print(f\" pipeline = joblib.load('artifacts/pipeline_final.joblib')\")\n",
    "print(f\" params = joblib.load('artifacts/parametres_decision.joblib')\")\n",
    "print(f\" feature_names = joblib.load('artifacts/feature_names.joblib')\")\n",
    "print(f\" seuil = params['seuil_optimal']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RÉSUMÉ FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n Fonction coût métier : 10×FN + 1×FP\")\n",
    "print(f\" {len(seuils)} seuils testés (0.000 à 1.000)\")\n",
    "print(f\" Seuil optimal identifié : {seuil_optimal:.4f}\")\n",
    "print(f\" Gain vs seuil défaut : {gain_pct:.2f}%\")\n",
    "print(f\" Pipeline final sauvegardé\")\n",
    "\n",
    "print(f\"\\n IMPACT BUSINESS:\")\n",
    "print(f\" Économie de {gain:,.0f} unités par batch de {len(y_valid):,} demandes\")\n",
    "if len(y_valid) > 0:\n",
    " economie_par_demande = gain / len(y_valid)\n",
    " print(f\" Soit {economie_par_demande:.4f} unités par demande\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Prochaine étape : Interprétabilité SHAP\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script d'extraction des figures - Notebook 05\n",
    "Optimisation du seuil métier (coût business)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_figures_from_notebook(notebook_path, output_dir):\n",
    " \"\"\"\n",
    " Extrait toutes les figures du notebook d'optimisation du seuil métier\n",
    " \"\"\"\n",
    " # Créer le dossier de sortie\n",
    " output_dir = Path(output_dir)\n",
    " output_dir.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    " # Charger le notebook\n",
    " with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    " notebook = json.load(f)\n",
    " \n",
    " figure_count = 0\n",
    " \n",
    " # Parcourir toutes les cellules\n",
    " for cell_idx, cell in enumerate(notebook['cells']):\n",
    " # Chercher les cellules avec outputs\n",
    " if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    " for output in cell['outputs']:\n",
    " # Chercher les images PNG\n",
    " if 'data' in output and 'image/png' in output['data']:\n",
    " figure_count += 1\n",
    " \n",
    " # Décoder l'image base64\n",
    " img_data = output['data']['image/png']\n",
    " img_bytes = base64.b64decode(img_data)\n",
    " \n",
    " # Déterminer le nom du fichier selon le contexte\n",
    " cell_source = ''.join(cell['source']).lower()\n",
    " \n",
    " if 'coût' in cell_source or 'cout' in cell_source or 'cost' in cell_source:\n",
    " filename = f'nb05_fig{figure_count:02d}_cout_vs_seuil.png'\n",
    " elif 'fn' in cell_source and 'fp' in cell_source:\n",
    " filename = f'nb05_fig{figure_count:02d}_fn_fp_evolution.png'\n",
    " elif 'optimal' in cell_source or 'seuil' in cell_source:\n",
    " filename = f'nb05_fig{figure_count:02d}_seuil_optimal.png'\n",
    " elif 'business' in cell_source or 'impact' in cell_source:\n",
    " filename = f'nb05_fig{figure_count:02d}_impact_business.png'\n",
    " else:\n",
    " filename = f'nb05_fig{figure_count:02d}_figure.png'\n",
    " \n",
    " # Sauvegarder l'image\n",
    " output_path = output_dir / filename\n",
    " with open(output_path, 'wb') as img_file:\n",
    " img_file.write(img_bytes)\n",
    " \n",
    " print(f\" Extrait : {filename}\")\n",
    " \n",
    " print(f\"\\n Total : {figure_count} figures extraites du Notebook 05\")\n",
    " return figure_count\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    " # Chemins\n",
    " NOTEBOOK_PATH = 'Barre_Stephane_P7_05_optimisation_seuil.ipynb'\n",
    " OUTPUT_DIR = 'outputs/figures_p7/notebook_05'\n",
    " \n",
    " # Extraction\n",
    " print(\" Extraction des figures du Notebook 05...\")\n",
    " print(f\" Notebook : {NOTEBOOK_PATH}\")\n",
    " print(f\" Sortie : {OUTPUT_DIR}\\n\")\n",
    " \n",
    " extract_figures_from_notebook(NOTEBOOK_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
